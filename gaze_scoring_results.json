[
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073094500_0.jpg",
    "bbox": [
      41.608941291360296,
      56.80940946691177,
      213.57176011029412,
      152.44800091911765
    ],
    "candidates": [
      {
        "text": "The laptop",
        "type": "generated"
      },
      {
        "text": "laptop computer",
        "type": "generated"
      },
      {
        "text": "The laptop on the left",
        "type": "generated"
      },
      {
        "text": "The laptop outlined by the red box (which I",
        "type": "generated"
      },
      {
        "text": "The open laptop",
        "type": "generated"
      },
      {
        "text": "laptop",
        "type": "generated"
      },
      {
        "text": "The laptop computer and its lime green case",
        "type": "generated"
      },
      {
        "text": "The highlighted computer",
        "type": "generated"
      },
      {
        "text": "The laptop with black keys and a silver back",
        "type": "generated"
      },
      {
        "text": "biggest laptop",
        "type": "gold"
      },
      {
        "text": "large laptop",
        "type": "gold"
      },
      {
        "text": "big laptop",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      92.8947742483699,
      35.22729253855292,
      34.78583346974773,
      59.179620724757946,
      133.5108599361524,
      87.41616007054498,
      89.69774700860839,
      56.49103911509037,
      66.98044699548095,
      53.72718075783447,
      25.797223693697536,
      25.797223693697536
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073104602_1.jpg",
    "bbox": [
      171.25,
      117.45999908447266,
      142.80499267578125,
      156.77499389648438
    ],
    "candidates": [
      {
        "text": "The boy with his arms raised",
        "type": "generated"
      },
      {
        "text": "The child in the blue shirt and gray pants",
        "type": "generated"
      },
      {
        "text": "The boy",
        "type": "generated"
      },
      {
        "text": "The child",
        "type": "generated"
      },
      {
        "text": "The child in the center",
        "type": "generated"
      },
      {
        "text": "The toddler",
        "type": "generated"
      },
      {
        "text": "The child in the center of image, wearing",
        "type": "generated"
      },
      {
        "text": "The child in the blue shirt",
        "type": "generated"
      },
      {
        "text": "Man holding child",
        "type": "generated"
      },
      {
        "text": "little boy with arm raised",
        "type": "gold"
      },
      {
        "text": "boy",
        "type": "gold"
      },
      {
        "text": "baby in arms",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      45.60733930603199,
      45.60733930603199,
      45.60733930603199,
      45.60733930603199,
      45.60733930603199,
      45.60733930603199,
      45.60733930603199,
      45.60733930603199,
      33.76001089580551,
      43.13751759160645,
      46.62013930072797,
      44.11418608350271
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073113541_2.jpg",
    "bbox": [
      214.3315078526327,
      9.731506974729772,
      217.35343201519692,
      306.3068546660959
    ],
    "candidates": [
      {
        "text": "The man",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "The man on the right",
        "type": "generated"
      },
      {
        "text": "The man in the suit",
        "type": "generated"
      },
      {
        "text": "The man in the image",
        "type": "generated"
      },
      {
        "text": "Man",
        "type": "generated"
      },
      {
        "text": "gentleman",
        "type": "generated"
      },
      {
        "text": "The man in the image is a middle-aged white",
        "type": "generated"
      },
      {
        "text": "Here's a concise referring expression for the object highlighted",
        "type": "generated"
      },
      {
        "text": "hot dude",
        "type": "gold"
      },
      {
        "text": "man",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      93.27947995160096,
      89.89474072614549,
      93.27947995160096,
      93.27947995160096,
      93.27947995160096,
      86.97462951530225,
      88.07545706276821,
      93.27947995160096,
      90.48064724644091,
      84.87756860459777,
      86.97462951530225
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073126497_3.jpg",
    "bbox": [
      136.0,
      0.0,
      239.63999938964844,
      314.9800109863281
    ],
    "candidates": [
      {
        "text": "The image with the red border",
        "type": "generated"
      },
      {
        "text": "The woman holding the child",
        "type": "generated"
      },
      {
        "text": "Mother and child",
        "type": "generated"
      },
      {
        "text": "The woman holding the baby",
        "type": "generated"
      },
      {
        "text": "The woman",
        "type": "generated"
      },
      {
        "text": "Woman and toddler",
        "type": "generated"
      },
      {
        "text": "The woman and child",
        "type": "generated"
      },
      {
        "text": "The woman and the baby",
        "type": "generated"
      },
      {
        "text": "The old lady and child",
        "type": "generated"
      },
      {
        "text": "lady",
        "type": "gold"
      },
      {
        "text": "older woman",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      1.2430955702237672,
      93.53472504555039,
      47.50689994986739,
      93.53472504555039,
      93.53472504555039,
      48.061563618672544,
      93.53472504555039,
      93.49256650415695,
      97.33017193763304,
      96.05957677612999,
      93.52029472611392
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073135365_4.jpg",
    "bbox": [
      120.57108316076807,
      71.37349691735693,
      155.489163685994,
      248.62651778990963
    ],
    "candidates": [
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "Woman",
        "type": "generated"
      },
      {
        "text": "The woman",
        "type": "generated"
      },
      {
        "text": "the man on left",
        "type": "generated"
      },
      {
        "text": "Man holding Wiimote",
        "type": "generated"
      },
      {
        "text": "The female player",
        "type": "generated"
      },
      {
        "text": "the red box",
        "type": "generated"
      },
      {
        "text": "The controlling device in her hands appears to be the",
        "type": "generated"
      },
      {
        "text": "A woman sitting",
        "type": "generated"
      },
      {
        "text": "GIRL BROWN",
        "type": "gold"
      },
      {
        "text": "person in blue jeans",
        "type": "gold"
      },
      {
        "text": "brown",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      94.31078481384176,
      94.93093900116298,
      92.97189193808066,
      91.61122750313127,
      191.5971664680412,
      93.20092669398966,
      93.27531628934562,
      37.9443061567983,
      92.97189193808066,
      92.45194530069926,
      36.57267049995058,
      94.03423688891765
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073148347_5.jpg",
    "bbox": [
      131.64666748046875,
      135.85333251953125,
      123.96666463216145,
      152.07333374023438
    ],
    "candidates": [
      {
        "text": "The batter",
        "type": "generated"
      },
      {
        "text": "batter",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "He who swings",
        "type": "generated"
      },
      {
        "text": "the batter",
        "type": "generated"
      },
      {
        "text": "Hitter",
        "type": "generated"
      },
      {
        "text": "Player at bat",
        "type": "generated"
      },
      {
        "text": "He who swung that wooden club",
        "type": "generated"
      },
      {
        "text": "The batter with the hat pulled down close to his",
        "type": "generated"
      },
      {
        "text": "man batting",
        "type": "gold"
      },
      {
        "text": "Batter",
        "type": "gold"
      },
      {
        "text": "the batter",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      54.97590229018041,
      59.672145333503785,
      64.17490496636815,
      61.15001985430556,
      54.97590229018041,
      54.59687206389328,
      59.87643384291072,
      54.61202922667208,
      235.38251010134348,
      59.57146591660136,
      59.7042781792991,
      54.97590229018041
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073173610_6.jpg",
    "bbox": [
      56.7920000076294,
      124.84000244140626,
      152.48800048828124,
      188.04799804687502
    ],
    "candidates": [
      {
        "text": "guy in white",
        "type": "generated"
      },
      {
        "text": "An older gentleman wearing a cap and white shirt",
        "type": "generated"
      },
      {
        "text": "The man in the pink shirt",
        "type": "generated"
      },
      {
        "text": "The person holding the phone",
        "type": "generated"
      },
      {
        "text": "The man wearing a hat and long-slee",
        "type": "generated"
      },
      {
        "text": "The person sitting down wearing a gray shirt and jeans",
        "type": "generated"
      },
      {
        "text": "The man in the hat",
        "type": "generated"
      },
      {
        "text": "The man in the white shirt and gray long sleeves",
        "type": "generated"
      },
      {
        "text": "older man",
        "type": "generated"
      },
      {
        "text": "boy on left white shirt",
        "type": "gold"
      },
      {
        "text": "guy in white shirt in back",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      59.632146505195344,
      61.55488690569847,
      61.55488690569847,
      179.0625397512955,
      61.55488690569847,
      61.55488690569847,
      61.55488690569847,
      61.55488690569847,
      60.564760212763844,
      59.632146505195344,
      51.34099874343438
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073178147_7.jpg",
    "bbox": [
      230.08480468750003,
      92.11733072916667,
      209.59572916666667,
      226.94401041666669
    ],
    "candidates": [
      {
        "text": "the toast",
        "type": "generated"
      },
      {
        "text": "The toast",
        "type": "generated"
      },
      {
        "text": "The bread",
        "type": "generated"
      },
      {
        "text": "The sandwich",
        "type": "generated"
      },
      {
        "text": "The bread slices",
        "type": "generated"
      },
      {
        "text": "The slice",
        "type": "generated"
      },
      {
        "text": "bread",
        "type": "generated"
      },
      {
        "text": "The item inside the red box is bread",
        "type": "generated"
      },
      {
        "text": "Two pieces of sandwich bread",
        "type": "generated"
      },
      {
        "text": "toast on left",
        "type": "gold"
      },
      {
        "text": "left side of sandwhich",
        "type": "gold"
      },
      {
        "text": "the bread in front cam",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      43.10416924746266,
      46.87176739979594,
      42.29787440499313,
      43.38698748680959,
      49.784478797920265,
      47.45134907650753,
      71.88241483502001,
      92.63806153617733,
      110.19121877830021,
      65.97469347545749,
      78.57490044439915,
      49.784478797920265
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073191159_8.jpg",
    "bbox": [
      244.5500030517578,
      98.94000244140625,
      65.2699966430664,
      220.9199981689453
    ],
    "candidates": [
      {
        "text": "The guy attempting to block the ball",
        "type": "generated"
      },
      {
        "text": "The middle guy",
        "type": "generated"
      },
      {
        "text": "The player in the middle",
        "type": "generated"
      },
      {
        "text": "The person in the middle",
        "type": "generated"
      },
      {
        "text": "The player in white and black",
        "type": "generated"
      },
      {
        "text": "The guy in the middle",
        "type": "generated"
      },
      {
        "text": "The man in the white sleeveless shirt, black",
        "type": "generated"
      },
      {
        "text": "The player",
        "type": "generated"
      },
      {
        "text": "The player with the red box around him",
        "type": "generated"
      },
      {
        "text": "man in black white shorts",
        "type": "gold"
      },
      {
        "text": "Middle person",
        "type": "gold"
      },
      {
        "text": "GUY IN BLACK NAD WHITE SHORTS",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      113.33817500228875,
      81.00824299332169,
      78.90757932269992,
      78.90757932269992,
      41.84756577492806,
      78.90757932269992,
      81.46545576120397,
      81.46545576120397,
      69.31693909335084,
      32.04675547816901,
      87.9046972620032,
      4.488499144277571
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073200187_9.jpg",
    "bbox": [
      78.56112663751463,
      106.42435185524006,
      192.00000914812648,
      129.4388767930328
    ],
    "candidates": [
      {
        "text": "The elephant with its trunk raised and mouth open",
        "type": "generated"
      },
      {
        "text": "The elephant in the middle",
        "type": "generated"
      },
      {
        "text": "The elephant in the front",
        "type": "generated"
      },
      {
        "text": "The elephant on the left",
        "type": "generated"
      },
      {
        "text": "The elephant with its head turned to the right",
        "type": "generated"
      },
      {
        "text": "The elephant closest to the right",
        "type": "generated"
      },
      {
        "text": "The elephant to the right",
        "type": "generated"
      },
      {
        "text": "The elephant on the left side",
        "type": "generated"
      },
      {
        "text": "The elephant with its trunk extended",
        "type": "generated"
      },
      {
        "text": "dark elephant in back",
        "type": "gold"
      },
      {
        "text": "second elephant from left",
        "type": "gold"
      },
      {
        "text": "elephant in backleft",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      62.976663014309494,
      64.24651078555264,
      33.60768326138766,
      46.135629146322806,
      190.40363756735738,
      190.53443914926794,
      172.3816658085708,
      44.602608013938635,
      92.9280823534448,
      40.03294812178937,
      18.08856041400617,
      49.3186368634273
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073209293_10.jpg",
    "bbox": [
      151.9087016704204,
      78.16456104542041,
      91.32973060951576,
      235.86786493524775
    ],
    "candidates": [
      {
        "text": "Person in the center wearing a black long-slee",
        "type": "generated"
      },
      {
        "text": "The man with the blue frisbee",
        "type": "generated"
      },
      {
        "text": "The person he's talking to",
        "type": "generated"
      },
      {
        "text": "The man holding the frisbee",
        "type": "generated"
      },
      {
        "text": "The young boy with blonde hair and the man wearing",
        "type": "generated"
      },
      {
        "text": "The person in the blue shirt",
        "type": "generated"
      },
      {
        "text": "The boy",
        "type": "generated"
      },
      {
        "text": "The boy in the blue shirt and plaid pants",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "man wearing black shirt",
        "type": "gold"
      },
      {
        "text": "crouching dude foreground",
        "type": "gold"
      },
      {
        "text": "the man talking to boy hold red frisbee",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      58.576064606280255,
      99.75789102515222,
      121.8655349647044,
      101.02523382328997,
      125.17327660539804,
      58.00745284320554,
      123.50532282427055,
      8.033322508270382,
      91.28915453805358,
      63.35961916818551,
      117.9067489511291,
      133.68928534344852
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073218396_11.jpg",
    "bbox": [
      105.59813084112149,
      0.0,
      389.9065420560747,
      46.945795077029786
    ],
    "candidates": [
      {
        "text": "The monitor",
        "type": "generated"
      },
      {
        "text": "The screen above the tablet",
        "type": "generated"
      },
      {
        "text": "monitor",
        "type": "generated"
      },
      {
        "text": "Monitor",
        "type": "generated"
      },
      {
        "text": "The monitor on the left",
        "type": "generated"
      },
      {
        "text": "The monitor at the top of image",
        "type": "generated"
      },
      {
        "text": "Upper monitor",
        "type": "generated"
      },
      {
        "text": "Dell monitor",
        "type": "generated"
      },
      {
        "text": "The monitor above the tablet that displays Dell logo",
        "type": "generated"
      },
      {
        "text": "monitor top out of view",
        "type": "gold"
      },
      {
        "text": "The top screen.",
        "type": "gold"
      },
      {
        "text": "monitor you can only see bottom part of at top of ic",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      9.949961121357136,
      11.31291793181313,
      9.949961121357136,
      9.949961121357136,
      244.19400472158134,
      16.955439727598844,
      10.22322502102625,
      11.31291793181313,
      9.949961121357136,
      12.438918539541168,
      9.46305359218058,
      131.4170398099144
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073231714_12.jpg",
    "bbox": [
      201.1270565257353,
      92.41599839154412,
      118.12141544117647,
      166.80658318014704
    ],
    "candidates": [
      {
        "text": "The batter",
        "type": "generated"
      },
      {
        "text": "batter",
        "type": "generated"
      },
      {
        "text": "Home plate",
        "type": "generated"
      },
      {
        "text": "the batter",
        "type": "generated"
      },
      {
        "text": "The batter and catcher",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "The batter on the umpire",
        "type": "generated"
      },
      {
        "text": "Home run position",
        "type": "generated"
      },
      {
        "text": "The batter at home plate",
        "type": "generated"
      },
      {
        "text": "batter",
        "type": "gold"
      },
      {
        "text": "BATTER",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      46.386460647217746,
      54.45482779947063,
      9.153437102402961,
      50.946030863921536,
      46.386460647217746,
      63.08431115363647,
      46.386460647217746,
      42.35939237704377,
      46.386460647217746,
      54.45482779947063,
      54.45482779947063
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073257013_13.jpg",
    "bbox": [
      147.5299997329712,
      197.47500610351562,
      132.61500549316406,
      122.5250015258789
    ],
    "candidates": [
      {
        "text": "The person with gray hair in the front",
        "type": "generated"
      },
      {
        "text": "The person with the red box around them",
        "type": "generated"
      },
      {
        "text": "person",
        "type": "generated"
      },
      {
        "text": "The blonde-headed person",
        "type": "generated"
      },
      {
        "text": "woman with short blonde hair",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "A guy with blonde hair",
        "type": "generated"
      },
      {
        "text": "lady with short blonde hair",
        "type": "generated"
      },
      {
        "text": "The person at the bottom with long blonde hair looking",
        "type": "generated"
      },
      {
        "text": "person with blue shirt",
        "type": "gold"
      },
      {
        "text": "blue shirt",
        "type": "gold"
      },
      {
        "text": "bottom man in blue",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      23.887792576327154,
      49.87988596436512,
      39.22662003363766,
      27.87083477831162,
      28.65808131153751,
      40.04956528212033,
      32.84557154186574,
      26.660701672345752,
      43.235352701604405,
      23.271519837277918,
      24.98166706568176,
      27.393064941341766
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073266129_14.jpg",
    "bbox": [
      118.07775678790985,
      52.12927217505855,
      47.790164277480976,
      198.3700325673302
    ],
    "candidates": [
      {
        "text": "The young kid in black",
        "type": "generated"
      },
      {
        "text": "The skater on the left",
        "type": "generated"
      },
      {
        "text": "The person in the red box is highlighted by",
        "type": "generated"
      },
      {
        "text": "The person in the middle wearing black",
        "type": "generated"
      },
      {
        "text": "The boy wearing a grayish green shirt",
        "type": "generated"
      },
      {
        "text": "The person in black is looking upward",
        "type": "generated"
      },
      {
        "text": "The two young Asian men standing in the middle-left",
        "type": "generated"
      },
      {
        "text": "The kid in the black t-shirt",
        "type": "generated"
      },
      {
        "text": "The kid between the white guy on left and",
        "type": "generated"
      },
      {
        "text": "man left arms crossed",
        "type": "gold"
      },
      {
        "text": "man with arms crossed",
        "type": "gold"
      },
      {
        "text": "guy with arms crossed",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      75.12748838726779,
      74.57160354431589,
      80.53759701399646,
      77.98624093954155,
      113.2455693438026,
      241.86232907476597,
      75.12748838726779,
      75.12748838726779,
      80.20835508347237,
      74.16032389706257,
      49.2155184171135,
      71.32051160792426
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073270691_15.jpg",
    "bbox": [
      66.72037493596312,
      76.23044587968384,
      196.59390094408667,
      166.6323230752342
    ],
    "candidates": [
      {
        "text": "The lamb",
        "type": "generated"
      },
      {
        "text": "The highlighted lamb",
        "type": "generated"
      },
      {
        "text": "The lamb on the left",
        "type": "generated"
      },
      {
        "text": "The sheep",
        "type": "generated"
      },
      {
        "text": "The woolly animal",
        "type": "generated"
      },
      {
        "text": "Herd",
        "type": "generated"
      },
      {
        "text": "The lamb that's standing",
        "type": "generated"
      },
      {
        "text": "The little black lamb in the red-outlined box",
        "type": "generated"
      },
      {
        "text": "The highlighted black lamb",
        "type": "generated"
      },
      {
        "text": "left goat",
        "type": "gold"
      },
      {
        "text": "left guy",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      72.55209127645723,
      28.201142557816883,
      72.55209127645723,
      138.0990185381185,
      72.55209127645723,
      152.672090252776,
      72.55209127645723,
      25.283579765869437,
      72.55209127645723,
      52.03013864957675,
      51.602313261847144
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073279604_16.jpg",
    "bbox": [
      151.98079956054687,
      82.771201171875,
      88.729599609375,
      90.1183984375
    ],
    "candidates": [
      {
        "text": "One of the apples",
        "type": "generated"
      },
      {
        "text": "The apple in the front left of bowl",
        "type": "generated"
      },
      {
        "text": "The apple to the left of bananas",
        "type": "generated"
      },
      {
        "text": "The apple",
        "type": "generated"
      },
      {
        "text": "The apple in the middle",
        "type": "generated"
      },
      {
        "text": "The apple to the left",
        "type": "generated"
      },
      {
        "text": "An apple",
        "type": "generated"
      },
      {
        "text": "The apple in the bowl",
        "type": "generated"
      },
      {
        "text": "The red apple",
        "type": "generated"
      },
      {
        "text": "apple on left",
        "type": "gold"
      },
      {
        "text": "first apple on left side",
        "type": "gold"
      },
      {
        "text": "Apple far left",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      11.518299478248771,
      12.218710462672647,
      11.827788164768007,
      12.654442317645861,
      77.58234736633476,
      11.827788164768007,
      13.102511233371503,
      11.015706303756746,
      8.527008802659111,
      0.79275492469336,
      11.070230818308449,
      8.677001087393375
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073288596_17.jpg",
    "bbox": [
      43.0,
      163.23333740234375,
      144.53999837239581,
      135.19332885742188
    ],
    "candidates": [
      {
        "text": "Snowboard",
        "type": "generated"
      },
      {
        "text": "Snowboard attached to ankle",
        "type": "generated"
      },
      {
        "text": "The binding",
        "type": "generated"
      },
      {
        "text": "The boot of my snowboard",
        "type": "generated"
      },
      {
        "text": "The snowboard",
        "type": "generated"
      },
      {
        "text": "A snowboard",
        "type": "generated"
      },
      {
        "text": "The boot",
        "type": "generated"
      },
      {
        "text": "The snowboarder's front right boot and heel",
        "type": "generated"
      },
      {
        "text": "The tip of the snowboard",
        "type": "generated"
      },
      {
        "text": "legs on left",
        "type": "gold"
      },
      {
        "text": "black pants on bottom leaning",
        "type": "gold"
      },
      {
        "text": "black object lower left corner",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      163.02696172927818,
      43.45831413672892,
      45.0633455757738,
      43.452128512814106,
      159.65629414729068,
      148.65153287362875,
      43.45050828184134,
      47.165931962796115,
      133.07638055792725,
      19.08946464491679,
      10.330121606170891,
      37.42288670681616
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073297578_18.jpg",
    "bbox": [
      371.1066691080729,
      137.25999959309894,
      98.55999755859375,
      134.66666666666666
    ],
    "candidates": [
      {
        "text": "The umpire",
        "type": "generated"
      },
      {
        "text": "Umpire",
        "type": "generated"
      },
      {
        "text": "The catcher",
        "type": "generated"
      },
      {
        "text": "home plate umpire",
        "type": "generated"
      },
      {
        "text": "umpire",
        "type": "generated"
      },
      {
        "text": "Home plate umpire",
        "type": "generated"
      },
      {
        "text": "the umpire",
        "type": "generated"
      },
      {
        "text": "Behind home plate",
        "type": "generated"
      },
      {
        "text": "The person in the catcher's pose is crou",
        "type": "generated"
      },
      {
        "text": "umpire",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      42.14798289677346,
      42.28895177249854,
      85.76482801992628,
      81.98258886619895,
      42.28895177249854,
      38.95740149878509,
      42.28895177249854,
      85.13842238657604,
      80.8000382872746,
      42.28895177249854
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073314704_19.jpg",
    "bbox": [
      237.68000030517578,
      71.00499725341797,
      124.12999725341797,
      248.9949951171875
    ],
    "candidates": [
      {
        "text": "Waiter",
        "type": "generated"
      },
      {
        "text": "The chef",
        "type": "generated"
      },
      {
        "text": "The chef in the center",
        "type": "generated"
      },
      {
        "text": "The gentleman in the middle",
        "type": "generated"
      },
      {
        "text": "The chef behind or the area",
        "type": "generated"
      },
      {
        "text": "The chef at the pass",
        "type": "generated"
      },
      {
        "text": "The chef in the middle",
        "type": "generated"
      },
      {
        "text": "The chef in the white button-down jacket",
        "type": "generated"
      },
      {
        "text": "chef",
        "type": "generated"
      },
      {
        "text": "guy glasses",
        "type": "gold"
      },
      {
        "text": "man in the front",
        "type": "gold"
      },
      {
        "text": "chef in front",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      86.42162942862967,
      86.0586057981857,
      88.02939748169369,
      84.06770878085052,
      114.50955063943911,
      175.53492258207842,
      85.87582952741283,
      56.537852218580234,
      85.87582952741283,
      89.17841902808881,
      89.97361609525119,
      88.02939748169369
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073332329_20.jpg",
    "bbox": [
      96.0,
      150.99000549316406,
      120.36000061035156,
      169.00999450683594
    ],
    "candidates": [
      {
        "text": "The woman with long brunette hair",
        "type": "generated"
      },
      {
        "text": "the woman with brown hair to left",
        "type": "generated"
      },
      {
        "text": "The woman on the left",
        "type": "generated"
      },
      {
        "text": "The woman with long brown hair",
        "type": "generated"
      },
      {
        "text": "Woman on the far left",
        "type": "generated"
      },
      {
        "text": "The woman on the left of table",
        "type": "generated"
      },
      {
        "text": "The lady with brown hair",
        "type": "generated"
      },
      {
        "text": "Her",
        "type": "generated"
      },
      {
        "text": "The woman on the left with long hair",
        "type": "generated"
      },
      {
        "text": "person on bottom left",
        "type": "gold"
      },
      {
        "text": "person in bottom left corner",
        "type": "gold"
      },
      {
        "text": "PERSON IN PLAID SHIRT ON LEFT CORNER",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      161.44625245016687,
      163.8133463557396,
      168.45560593808872,
      161.44625245016687,
      169.4495888958384,
      169.09257575507053,
      163.22102695654712,
      164.40602314933946,
      164.02302365340708,
      43.56910444770337,
      43.92960463841424,
      12.172391903653779
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073336824_21.jpg",
    "bbox": [
      150.72000002861023,
      137.35000610351562,
      82.69499969482422,
      174.74000549316406
    ],
    "candidates": [
      {
        "text": "The fenced off area",
        "type": "generated"
      },
      {
        "text": "The leg",
        "type": "generated"
      },
      {
        "text": "The pants",
        "type": "generated"
      },
      {
        "text": "The ski",
        "type": "generated"
      },
      {
        "text": "The skis and poles",
        "type": "generated"
      },
      {
        "text": "The lower leg and foot of the skier in",
        "type": "generated"
      },
      {
        "text": "Ski pole",
        "type": "generated"
      },
      {
        "text": "Knee",
        "type": "generated"
      },
      {
        "text": "The lower half of skier number 93",
        "type": "generated"
      },
      {
        "text": "yellow shirt",
        "type": "gold"
      },
      {
        "text": "yellow sleeve guy",
        "type": "gold"
      },
      {
        "text": "left edge of pic: cutoff person",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      63.09459784966908,
      92.24592584839657,
      91.18270654627685,
      130.61382734937553,
      73.84361910205111,
      111.32518278010755,
      135.41223281639378,
      89.73254459884951,
      57.87479534402044,
      52.87569397661587,
      56.82995574091704,
      51.11203947725384
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073341391_22.jpg",
    "bbox": [
      245.61312573185015,
      102.57236168032787,
      57.779858341261715,
      177.7686232984485
    ],
    "candidates": [
      {
        "text": "The two men in front of the bus",
        "type": "generated"
      },
      {
        "text": "The two men standing in front of the bus",
        "type": "generated"
      },
      {
        "text": "The two men",
        "type": "generated"
      },
      {
        "text": "The two men near the bus door",
        "type": "generated"
      },
      {
        "text": "The man in the black shirt and khaki pants",
        "type": "generated"
      },
      {
        "text": "The two men standing outside the bus",
        "type": "generated"
      },
      {
        "text": "The two men at the center of image",
        "type": "generated"
      },
      {
        "text": "The men at the bus door",
        "type": "generated"
      },
      {
        "text": "The two gentlemen getting off the bus",
        "type": "generated"
      },
      {
        "text": "left guy",
        "type": "gold"
      },
      {
        "text": "guy on left",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      79.88645969704503,
      77.9245751510304,
      77.9245751510304,
      77.9245751510304,
      18.77124079262776,
      75.23279007958863,
      79.59927137322138,
      80.17588896113007,
      78.47341667105047,
      73.83619390692226,
      71.44079922798144
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073350496_23.jpg",
    "bbox": [
      200.1199951171875,
      19.413333892822266,
      109.54667154947916,
      218.37333170572916
    ],
    "candidates": [
      {
        "text": "The traffic light",
        "type": "generated"
      },
      {
        "text": "The stoplight",
        "type": "generated"
      },
      {
        "text": "traffic light",
        "type": "generated"
      },
      {
        "text": "The traffic light in the middle",
        "type": "generated"
      },
      {
        "text": "Traffic light",
        "type": "generated"
      },
      {
        "text": "The light",
        "type": "generated"
      },
      {
        "text": "Three-light device",
        "type": "generated"
      },
      {
        "text": "The light on the pole",
        "type": "generated"
      },
      {
        "text": "The traffic light in the center",
        "type": "generated"
      },
      {
        "text": "traffic light",
        "type": "gold"
      },
      {
        "text": "yellow signal",
        "type": "gold"
      },
      {
        "text": "stop light",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      15.131551107898387,
      14.376781300365716,
      11.61928392404209,
      15.131551107898387,
      11.61928392404209,
      12.349271283165333,
      9.664539904939616,
      11.70871414985097,
      13.220306335240782,
      11.61928392404209,
      13.762982923282504,
      155.93760174880185
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073363481_24.jpg",
    "bbox": [
      236.3133341471354,
      65.94000244140625,
      69.09333292643228,
      155.18666585286456
    ],
    "candidates": [
      {
        "text": "The glass with the most wine in it",
        "type": "generated"
      },
      {
        "text": "The middle glass",
        "type": "generated"
      },
      {
        "text": "Wine glass closest to the viewer",
        "type": "generated"
      },
      {
        "text": "The bottle opener",
        "type": "generated"
      },
      {
        "text": "The wine glass closest to the viewer",
        "type": "generated"
      },
      {
        "text": "The highlighted object can be referred to as follows:",
        "type": "generated"
      },
      {
        "text": "The glass",
        "type": "generated"
      },
      {
        "text": "The glass in the middle",
        "type": "generated"
      },
      {
        "text": "The wine glass second from the left",
        "type": "generated"
      },
      {
        "text": "center wine glass - tiny amount of dark wine",
        "type": "gold"
      },
      {
        "text": "3RD GLASS",
        "type": "gold"
      },
      {
        "text": "glass in front of food",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      25.318928551123403,
      25.954352472133184,
      105.33424398797646,
      25.21761585136255,
      105.33424398797646,
      25.855529746994662,
      105.33424398797646,
      25.318928551123403,
      89.31730773599293,
      25.954352472133184,
      25.318928551123403,
      25.21761585136255
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073368040_25.jpg",
    "bbox": [
      224.43839843749998,
      61.58080078125,
      111.123203125,
      126.40639648437501
    ],
    "candidates": [
      {
        "text": "The pitcher",
        "type": "generated"
      },
      {
        "text": "The player",
        "type": "generated"
      },
      {
        "text": "The first baseman",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "The pitcher's hand",
        "type": "generated"
      },
      {
        "text": "The catcher",
        "type": "generated"
      },
      {
        "text": "The player at bat wearing red, white, and",
        "type": "generated"
      },
      {
        "text": "Behind the mitt",
        "type": "generated"
      },
      {
        "text": "The caught ball",
        "type": "generated"
      },
      {
        "text": "pitcher",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      58.90976778753462,
      61.16016406764497,
      41.70271855684291,
      56.764610176863286,
      62.162947973702565,
      78.41465579393467,
      99.35247175853878,
      44.829432561446175,
      56.14120861302552,
      56.40651688441018
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073381044_26.jpg",
    "bbox": [
      209.23238554772976,
      149.24463852229212,
      64.7772443842314,
      170.75536147770788
    ],
    "candidates": [
      {
        "text": "The boy sitting with his arms crossed in front of",
        "type": "generated"
      },
      {
        "text": "The boy",
        "type": "generated"
      },
      {
        "text": "The child",
        "type": "generated"
      },
      {
        "text": "The boy in the gray shirt",
        "type": "generated"
      },
      {
        "text": "The boy in the middle",
        "type": "generated"
      },
      {
        "text": "The child in the center of photograph",
        "type": "generated"
      },
      {
        "text": "A person",
        "type": "generated"
      },
      {
        "text": "Child in gray shirt",
        "type": "generated"
      },
      {
        "text": "The boy in the brown shirt with his hand over",
        "type": "generated"
      },
      {
        "text": "The sitting boy.",
        "type": "gold"
      },
      {
        "text": "close middle kid",
        "type": "gold"
      },
      {
        "text": "center sitting person",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      68.45794608752554,
      68.45794608752554,
      68.45794608752554,
      60.807712986687385,
      66.54474492069043,
      65.26949930289965,
      68.45794608752554,
      66.46524857706437,
      60.807712986687385,
      63.35699040586143,
      63.273489117794206,
      67.82016966853065
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073390247_27.jpg",
    "bbox": [
      255.1252564709596,
      34.95434323705808,
      64.14222301136364,
      162.8832366635101
    ],
    "candidates": [
      {
        "text": "The central mounted police officer",
        "type": "generated"
      },
      {
        "text": "The central rider",
        "type": "generated"
      },
      {
        "text": "The central officer",
        "type": "generated"
      },
      {
        "text": "The officer in the center",
        "type": "generated"
      },
      {
        "text": "The man in the middle",
        "type": "generated"
      },
      {
        "text": "The man on the third horse from left",
        "type": "generated"
      },
      {
        "text": "The police officer in the foreground",
        "type": "generated"
      },
      {
        "text": "The man in the middle holding gun and steering",
        "type": "generated"
      },
      {
        "text": "The central figure riding a white horse",
        "type": "generated"
      },
      {
        "text": "middle guy on white horse",
        "type": "gold"
      },
      {
        "text": "2nd from right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      67.18461005167757,
      67.18461005167757,
      67.18461005167757,
      67.18461005167757,
      60.7918376076523,
      61.07583205631942,
      67.2386710562615,
      3.03753073194164,
      67.18461005167757,
      61.20389826478441,
      60.715972024391434
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073394813_28.jpg",
    "bbox": [
      17.54379386812518,
      106.42435185524006,
      203.39859759221312,
      213.5756367096019
    ],
    "candidates": [
      {
        "text": "The bed on the left",
        "type": "generated"
      },
      {
        "text": "the bed",
        "type": "generated"
      },
      {
        "text": "The bed",
        "type": "generated"
      },
      {
        "text": "the backpack",
        "type": "generated"
      },
      {
        "text": "The item within the red box highlight appears to be",
        "type": "generated"
      },
      {
        "text": "A black backpack",
        "type": "generated"
      },
      {
        "text": "The mattress",
        "type": "generated"
      },
      {
        "text": "The highlighted object is the black bag with a white",
        "type": "generated"
      },
      {
        "text": "The bed on the left side of image",
        "type": "generated"
      },
      {
        "text": "left bed",
        "type": "gold"
      },
      {
        "text": "BED ON LEFT",
        "type": "gold"
      },
      {
        "text": "L bed",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      146.2628413098157,
      70.88131136811246,
      73.17430006913335,
      48.33144078547946,
      39.021048909978916,
      51.1860359771691,
      61.501288803758094,
      15.447308954526928,
      146.2628413098157,
      62.100857375518025,
      23.10667505707059,
      59.78070891988591
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073412770_29.jpg",
    "bbox": [
      10.368000030517578,
      162.98399658203127,
      181.80799560546876,
      114.91199951171876
    ],
    "candidates": [
      {
        "text": "The horse on the left",
        "type": "generated"
      },
      {
        "text": "The brown horse with white socks on its feet",
        "type": "generated"
      },
      {
        "text": "The horse",
        "type": "generated"
      },
      {
        "text": "The horse in the red box",
        "type": "generated"
      },
      {
        "text": "The horse on the left side of image is",
        "type": "generated"
      },
      {
        "text": "The horse to the left of man",
        "type": "generated"
      },
      {
        "text": "That horse",
        "type": "generated"
      },
      {
        "text": "The blue box",
        "type": "generated"
      },
      {
        "text": "The horse being judged",
        "type": "generated"
      },
      {
        "text": "Horse on the left.",
        "type": "gold"
      },
      {
        "text": "left horse",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      42.67325591991046,
      289.80704304377235,
      271.0597203341335,
      49.61185910041997,
      33.499076613112344,
      44.420990046864894,
      264.6343966188185,
      182.9512517340512,
      272.9573547766778,
      42.094013535105844,
      66.83035098193535
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073421826_30.jpg",
    "bbox": [
      81.87623506433823,
      73.84847196691176,
      318.5618795955882,
      212.13363970588236
    ],
    "candidates": [
      {
        "text": "The train",
        "type": "generated"
      },
      {
        "text": "The front train",
        "type": "generated"
      },
      {
        "text": "train",
        "type": "generated"
      },
      {
        "text": "The train at the station",
        "type": "generated"
      },
      {
        "text": "the train",
        "type": "generated"
      },
      {
        "text": "The train engine",
        "type": "generated"
      },
      {
        "text": "The train in the middle of photo",
        "type": "generated"
      },
      {
        "text": "Train",
        "type": "generated"
      },
      {
        "text": "The train in the red box is a green and",
        "type": "generated"
      },
      {
        "text": "green train",
        "type": "gold"
      },
      {
        "text": "green and yellow train",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      54.34725167997682,
      70.59594120887364,
      50.657579659232134,
      50.03780372398138,
      50.95099559717373,
      85.00797933406524,
      29.42040479170743,
      50.657579659232134,
      42.343241809425194,
      36.996672312865776,
      21.78027110217853
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073435088_31.jpg",
    "bbox": [
      377.378671875,
      5.085866699218751,
      89.89013020833333,
      247.36427083333334
    ],
    "candidates": [
      {
        "text": "The man with his legs crossed",
        "type": "generated"
      },
      {
        "text": "The person on the right",
        "type": "generated"
      },
      {
        "text": "The man on the right",
        "type": "generated"
      },
      {
        "text": "The person in black pants",
        "type": "generated"
      },
      {
        "text": "The person in the red box",
        "type": "generated"
      },
      {
        "text": "The man in the white shirt",
        "type": "generated"
      },
      {
        "text": "The man on the right wearing a white shirt",
        "type": "generated"
      },
      {
        "text": "The man wearing an ID, standing at the back",
        "type": "generated"
      },
      {
        "text": "The person in the black slacks",
        "type": "generated"
      },
      {
        "text": "far right dud",
        "type": "gold"
      },
      {
        "text": "man holding a cup",
        "type": "gold"
      },
      {
        "text": "guy on far right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      170.23719559450478,
      89.68331730993796,
      93.88748140175568,
      31.661314584442277,
      91.28074252435917,
      151.89159428343953,
      91.20992712673889,
      156.6459116711903,
      90.70059230998267,
      97.05000491889058,
      67.52822386453202,
      91.91438733140032
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073444208_32.jpg",
    "bbox": [
      221.22717085040986,
      81.49882903981265,
      106.69414153981265,
      201.03794642857144
    ],
    "candidates": [
      {
        "text": "The motorcycle",
        "type": "generated"
      },
      {
        "text": "The boy in the white t-shirt and brown pants",
        "type": "generated"
      },
      {
        "text": "The boy on the motorcycle",
        "type": "generated"
      },
      {
        "text": "The boy looking at the motorcycle",
        "type": "generated"
      },
      {
        "text": "The boy with blonde hair and the motorcycle",
        "type": "generated"
      },
      {
        "text": "The motorbike",
        "type": "generated"
      },
      {
        "text": "The young boy",
        "type": "generated"
      },
      {
        "text": "The motorcycle behind the two children in center",
        "type": "generated"
      },
      {
        "text": "The child and motorcycle",
        "type": "generated"
      },
      {
        "text": "kid in white shirt in the middle",
        "type": "gold"
      },
      {
        "text": "middle",
        "type": "gold"
      },
      {
        "text": "kid touching bike",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      27.91081357181274,
      65.64364707197703,
      98.26590292759191,
      98.26590292759191,
      99.49538105834564,
      32.80848223063598,
      71.39510825594068,
      95.98953365726555,
      78.34053417037678,
      63.879313004535,
      77.87579638108082,
      68.74091569670341
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073453336_33.jpg",
    "bbox": [
      193.61502118177816,
      170.42629474765258,
      127.28638268412558,
      145.97558822990024
    ],
    "candidates": [
      {
        "text": "Pizza slice",
        "type": "generated"
      },
      {
        "text": "Pizza slice in the lower right quadrant",
        "type": "generated"
      },
      {
        "text": "Pizza slice number four",
        "type": "generated"
      },
      {
        "text": "slice of pizza",
        "type": "generated"
      },
      {
        "text": "the slice of pizza directly beneath center",
        "type": "generated"
      },
      {
        "text": "The pizza slice at the bottom center of",
        "type": "generated"
      },
      {
        "text": "The slice of pizza in the bottom middle",
        "type": "generated"
      },
      {
        "text": "The slice in the lower center of pizza",
        "type": "generated"
      },
      {
        "text": "The slice in the lower center-right of pizza",
        "type": "generated"
      },
      {
        "text": "bottom slice",
        "type": "gold"
      },
      {
        "text": "the slice of pizza on the very bottom of the box",
        "type": "gold"
      },
      {
        "text": "sorry. slice at 6 o'clock",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      52.70910831929353,
      11.80135332030211,
      43.752184258585054,
      52.71016649274552,
      31.110269928308256,
      30.961468059387666,
      43.858882451503824,
      43.74045452178983,
      45.36479164685358,
      1.3192742983076335,
      7.272919437935576,
      39.99182353688849
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073462457_34.jpg",
    "bbox": [
      94.24000244140626,
      115.552001953125,
      116.08800048828125,
      180.96800537109377
    ],
    "candidates": [
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "The batter",
        "type": "generated"
      },
      {
        "text": "First baseman",
        "type": "generated"
      },
      {
        "text": "batter",
        "type": "generated"
      },
      {
        "text": "home plate",
        "type": "generated"
      },
      {
        "text": "The batter who just hit the ball",
        "type": "generated"
      },
      {
        "text": "The guy at bat",
        "type": "generated"
      },
      {
        "text": "Hitter",
        "type": "generated"
      },
      {
        "text": "number 24",
        "type": "generated"
      },
      {
        "text": "batter",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      62.74085946294066,
      62.70265649594498,
      127.4546318247633,
      63.38020457592393,
      127.03359955450156,
      62.70265649594498,
      61.401268694331286,
      63.34238721098195,
      47.93030306039142,
      63.38020457592393
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073483551_35.jpg",
    "bbox": [
      140.2800006866455,
      20.764999389648438,
      85.95999908447266,
      100.41000366210938
    ],
    "candidates": [
      {
        "text": "The man on the left wearing all black",
        "type": "generated"
      },
      {
        "text": "The player",
        "type": "generated"
      },
      {
        "text": "The goalkeeper",
        "type": "generated"
      },
      {
        "text": "The keeper",
        "type": "generated"
      },
      {
        "text": "The person in the red box",
        "type": "generated"
      },
      {
        "text": "He",
        "type": "generated"
      },
      {
        "text": "His arm",
        "type": "generated"
      },
      {
        "text": "The goal tender",
        "type": "generated"
      },
      {
        "text": "The goalie",
        "type": "generated"
      },
      {
        "text": "boy in black shirt",
        "type": "gold"
      },
      {
        "text": "head of top guy",
        "type": "gold"
      },
      {
        "text": "guy on top",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      37.987310598822,
      66.19951994055167,
      37.987310598822,
      37.987310598822,
      37.987310598822,
      41.10741738649636,
      15.848951406070963,
      33.401518355038874,
      37.987310598822,
      24.779130941242656,
      39.19398624709692,
      36.422088927515865
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073492463_36.jpg",
    "bbox": [
      43.0,
      108.586669921875,
      137.36666870117188,
      143.72000122070312
    ],
    "candidates": [
      {
        "text": "A pillow",
        "type": "generated"
      },
      {
        "text": "The sofa",
        "type": "generated"
      },
      {
        "text": "The armchair",
        "type": "generated"
      },
      {
        "text": "The couch where people are resting",
        "type": "generated"
      },
      {
        "text": "The ottoman",
        "type": "generated"
      },
      {
        "text": "The pillow on the left side of couch",
        "type": "generated"
      },
      {
        "text": "The pillow on the beige couch left",
        "type": "generated"
      },
      {
        "text": "The blanket on the chair",
        "type": "generated"
      },
      {
        "text": "The chair in the living room with turquoise sh",
        "type": "generated"
      },
      {
        "text": "sofa on far left with white pillow",
        "type": "gold"
      },
      {
        "text": "tan couch with white pillow",
        "type": "gold"
      },
      {
        "text": "left couche behind white chair",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      42.291655392783376,
      87.12371106625159,
      37.81804536510237,
      57.87682471950184,
      24.820890715145406,
      54.39837735906689,
      37.81804536510237,
      3.273893981093587,
      30.01430913465594,
      40.372251712803234,
      37.81804536510237,
      92.68966017940964
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073497031_37.jpg",
    "bbox": [
      298.56903765690373,
      89.08452373169456,
      100.49205061780857,
      224.50209613624477
    ],
    "candidates": [
      {
        "text": "Hamburger",
        "type": "generated"
      },
      {
        "text": "Hamburge\u00f1a de queso",
        "type": "generated"
      },
      {
        "text": "The hot dog",
        "type": "generated"
      },
      {
        "text": "hotdog",
        "type": "generated"
      },
      {
        "text": "she",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "El hot dog",
        "type": "generated"
      },
      {
        "text": "Hamb\u00fargueras Queso y",
        "type": "generated"
      },
      {
        "text": "Hamb\u00farguesa con queso",
        "type": "generated"
      },
      {
        "text": "woman",
        "type": "gold"
      },
      {
        "text": "girl",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      85.01916784861027,
      90.66498778710479,
      81.87459717523753,
      80.6035941977846,
      83.10240009497107,
      83.10240009497107,
      79.22390470315725,
      97.99370720017356,
      90.66498778710479,
      83.52093721838575,
      83.52093721838575
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073506004_38.jpg",
    "bbox": [
      285.8333333333333,
      244.3133341471354,
      153.88666788736978,
      75.68666585286458
    ],
    "candidates": [
      {
        "text": "The certificate",
        "type": "generated"
      },
      {
        "text": "The document in the mail, specifically orange envelope",
        "type": "generated"
      },
      {
        "text": "The item highlighted by the red box is a",
        "type": "generated"
      },
      {
        "text": "Vermont tax appeal letter",
        "type": "generated"
      },
      {
        "text": "The document with the official seal in upper left",
        "type": "generated"
      },
      {
        "text": "The document in the orange envelope",
        "type": "generated"
      },
      {
        "text": "The document on the bottom right of bed with",
        "type": "generated"
      },
      {
        "text": "The document on the right side of bed next",
        "type": "generated"
      },
      {
        "text": "Property Tax Assessment Complaint",
        "type": "generated"
      },
      {
        "text": "right pape",
        "type": "gold"
      },
      {
        "text": "town of randolph letter",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      21.742716434598265,
      123.40701935497972,
      25.371461457649954,
      16.42299203026605,
      53.14959601599696,
      114.0737944860015,
      23.40915178356923,
      23.40915178356923,
      48.20894015935923,
      15.984629261976949,
      21.78537517457555
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073515110_39.jpg",
    "bbox": [
      129.72000002861023,
      52.54999923706055,
      96.79499816894531,
      148.0800018310547
    ],
    "candidates": [
      {
        "text": "The skateboarder in mid-air wearing blue jean cap",
        "type": "generated"
      },
      {
        "text": "The skateboarder",
        "type": "generated"
      },
      {
        "text": "The person doing a front flip off the ramp",
        "type": "generated"
      },
      {
        "text": "The skateboarder performing a trick over the skateboard with",
        "type": "generated"
      },
      {
        "text": "The skateboarder turning",
        "type": "generated"
      },
      {
        "text": "The person grling the ramp",
        "type": "generated"
      },
      {
        "text": "The person falling off the skateboard",
        "type": "generated"
      },
      {
        "text": "The skateboarder in action",
        "type": "generated"
      },
      {
        "text": "skater",
        "type": "generated"
      },
      {
        "text": "left skateboarder",
        "type": "gold"
      },
      {
        "text": "very left kid",
        "type": "gold"
      },
      {
        "text": "left person",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      73.18070709145884,
      64.87234150965229,
      82.24709280761438,
      80.21274642011363,
      64.87234150965229,
      9.61395511893732,
      68.61679289794337,
      73.18070709145884,
      68.68138113684725,
      12.913767960254082,
      33.977601347817455,
      32.25985419628038
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073524088_40.jpg",
    "bbox": [
      287.87333170572913,
      64.10666910807291,
      67.89999898274739,
      181.3133341471354
    ],
    "candidates": [
      {
        "text": "The lady with black hair in a suit",
        "type": "generated"
      },
      {
        "text": "The person with the black briefcase",
        "type": "generated"
      },
      {
        "text": "The woman in the black suit",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "The woman with black salad",
        "type": "generated"
      },
      {
        "text": "The man carrying the suitcase",
        "type": "generated"
      },
      {
        "text": "The person with the bag",
        "type": "generated"
      },
      {
        "text": "The woman with her back turned",
        "type": "generated"
      },
      {
        "text": "The person pulling the suitcase",
        "type": "generated"
      },
      {
        "text": "black shirt",
        "type": "gold"
      },
      {
        "text": "guy in blac shirt",
        "type": "gold"
      },
      {
        "text": "person in almost all black",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      68.36730515977045,
      51.361120550722404,
      51.18960109868516,
      68.36730515977045,
      58.82927893097401,
      67.99375367877558,
      62.38081486804128,
      73.51847196366145,
      65.66761628345314,
      39.74623916638752,
      28.1352755039679,
      71.59941416613809
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073528649_41.jpg",
    "bbox": [
      220.68499755859375,
      132.06500244140625,
      52.970001220703125,
      174.14999389648438
    ],
    "candidates": [
      {
        "text": "The man in the center",
        "type": "generated"
      },
      {
        "text": "The man in the gray Royals uniform",
        "type": "generated"
      },
      {
        "text": "The man in the middle",
        "type": "generated"
      },
      {
        "text": "The man in the blue shirt",
        "type": "generated"
      },
      {
        "text": "The man in the blue hat who is kneeling with",
        "type": "generated"
      },
      {
        "text": "The manager",
        "type": "generated"
      },
      {
        "text": "The man in the gray striped shirt",
        "type": "generated"
      },
      {
        "text": "The man standing on the steps",
        "type": "generated"
      },
      {
        "text": "The guy in front of the catcher",
        "type": "generated"
      },
      {
        "text": "guy in between the two players high fiving",
        "type": "gold"
      },
      {
        "text": "man under arms of players high fiving",
        "type": "gold"
      },
      {
        "text": "lower man in the middle of the higher two",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      69.45093000178468,
      69.45093000178468,
      69.45093000178468,
      62.00950634645906,
      68.8872562143231,
      69.45093000178468,
      69.45093000178468,
      69.45093000178468,
      67.00816421214319,
      67.58751127580115,
      61.40130037930017,
      58.939600366765696
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073537759_42.jpg",
    "bbox": [
      154.46826706099563,
      90.6293165344639,
      195.15798088758206,
      225.18336723878554
    ],
    "candidates": [
      {
        "text": "The girl brushing her teeth",
        "type": "generated"
      },
      {
        "text": "The middle girl",
        "type": "generated"
      },
      {
        "text": "The girl",
        "type": "generated"
      },
      {
        "text": "Girl brushing teeth",
        "type": "generated"
      },
      {
        "text": "The little girl in toothpaste",
        "type": "generated"
      },
      {
        "text": "The young girl in the foreground",
        "type": "generated"
      },
      {
        "text": "The girl in the middle",
        "type": "generated"
      },
      {
        "text": "The girl with shoulder-length brown hair",
        "type": "generated"
      },
      {
        "text": "The girl with toothbrush in mouth",
        "type": "generated"
      },
      {
        "text": "girl brushing teeth",
        "type": "gold"
      },
      {
        "text": "girl brush front",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      59.93268481902252,
      67.76395856887956,
      66.10616575835085,
      62.43728878165706,
      66.10616575835085,
      66.10616575835085,
      66.10616575835085,
      69.46616743839473,
      56.07202393457523,
      59.82665249954399,
      62.14342249307161
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073551073_43.jpg",
    "bbox": [
      43.0,
      1.1466666857401528,
      196.45332845052081,
      120.03333536783853
    ],
    "candidates": [
      {
        "text": "Umbrella",
        "type": "generated"
      },
      {
        "text": "The umbrella",
        "type": "generated"
      },
      {
        "text": "The upper left-hand part",
        "type": "generated"
      },
      {
        "text": "a hot dog stand",
        "type": "generated"
      },
      {
        "text": "umbrella",
        "type": "generated"
      },
      {
        "text": "The highlighted hot dog cart",
        "type": "generated"
      },
      {
        "text": "Above the vendor's cart",
        "type": "generated"
      },
      {
        "text": "Hotdog stand",
        "type": "generated"
      },
      {
        "text": "the umbrella",
        "type": "generated"
      },
      {
        "text": "umbrella on left",
        "type": "gold"
      },
      {
        "text": "left umbrella",
        "type": "gold"
      },
      {
        "text": "umbrella on th left",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      15.396849747153652,
      15.766649933628555,
      33.85674755535519,
      143.12960913790207,
      10.894942072645875,
      122.15291077384983,
      7.8988951087991515,
      146.82134167178134,
      4.36863883450082,
      21.294073181610152,
      11.912576118251847,
      34.89037024826807
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073559708_44.jpg",
    "bbox": [
      16.72112674444494,
      82.69671086414318,
      198.46759921508215,
      45.30328741655663
    ],
    "candidates": [
      {
        "text": "The pizza",
        "type": "generated"
      },
      {
        "text": "Pizza",
        "type": "generated"
      },
      {
        "text": "The pizza with white cheese, likely mozzarella",
        "type": "generated"
      },
      {
        "text": "pizza, left side",
        "type": "generated"
      },
      {
        "text": "The pizza in the back",
        "type": "generated"
      },
      {
        "text": "The pizza in the top left of image",
        "type": "generated"
      },
      {
        "text": "The highlighted pizza",
        "type": "generated"
      },
      {
        "text": "The pizza slices at the top left",
        "type": "generated"
      },
      {
        "text": "The pizza in the back left",
        "type": "generated"
      },
      {
        "text": "top pizza",
        "type": "gold"
      },
      {
        "text": "farthest pizza",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      166.73780923434748,
      167.22295119894642,
      100.80431417281169,
      98.18776168608788,
      3.4957526010966067,
      12.160066042805877,
      3.3635684020656105,
      5.111925770585348,
      12.088892104436248,
      3.7344584749027807,
      172.08293071028538
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073568821_45.jpg",
    "bbox": [
      166.69316931935816,
      137.47412008281574,
      154.25590183423913,
      108.3362347146739
    ],
    "candidates": [
      {
        "text": "The food",
        "type": "generated"
      },
      {
        "text": "The toasted sandwich",
        "type": "generated"
      },
      {
        "text": "The front middle food item",
        "type": "generated"
      },
      {
        "text": "The object highlighted by the red box is:",
        "type": "generated"
      },
      {
        "text": "The highlighted item is the club sandwich in center",
        "type": "generated"
      },
      {
        "text": "The grilled sandwich",
        "type": "generated"
      },
      {
        "text": "The middle and highest-layered sandwich",
        "type": "generated"
      },
      {
        "text": "The sandwich",
        "type": "generated"
      },
      {
        "text": "The object highlighted by the red box is first",
        "type": "generated"
      },
      {
        "text": "left side of sandwhich",
        "type": "gold"
      },
      {
        "text": "blt sandwich",
        "type": "gold"
      },
      {
        "text": "grilled sandwich on left side of plate",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      28.132248396134685,
      19.858796318387427,
      22.282955612579183,
      28.132248396134685,
      27.60954092458129,
      12.235377422655347,
      23.102061126752833,
      27.589152504171413,
      28.132248396134685,
      20.65287245041938,
      17.74523016213435,
      14.76770458059024
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073577932_46.jpg",
    "bbox": [
      33.701531775409855,
      28.470897048516136,
      234.66433602297593,
      291.52910028036104
    ],
    "candidates": [
      {
        "text": "The woman in the lower left",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "The woman holding the knife",
        "type": "generated"
      },
      {
        "text": "The lady cutting the cake",
        "type": "generated"
      },
      {
        "text": "Woman with short hair",
        "type": "generated"
      },
      {
        "text": "The woman in the foreground on left side of",
        "type": "generated"
      },
      {
        "text": "The woman on the left",
        "type": "generated"
      },
      {
        "text": "Woman cutting cake",
        "type": "generated"
      },
      {
        "text": "The woman cake-cutting",
        "type": "generated"
      },
      {
        "text": "woman front left",
        "type": "gold"
      },
      {
        "text": "person cutting cake",
        "type": "gold"
      },
      {
        "text": "Woman left",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      86.46781779602009,
      84.54302674139099,
      70.85425912574951,
      140.81307641178418,
      92.4796528012039,
      84.54302674139099,
      86.46781779602009,
      80.190890942887,
      135.1553051728879,
      90.50873438438447,
      86.74560935486863,
      87.2529005776243
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073587044_47.jpg",
    "bbox": [
      278.8666585286458,
      191.2800089518229,
      190.80000813802081,
      125.12666829427083
    ],
    "candidates": [
      {
        "text": "The bananas",
        "type": "generated"
      },
      {
        "text": "bananas",
        "type": "generated"
      },
      {
        "text": "Bananas",
        "type": "generated"
      },
      {
        "text": "A banana",
        "type": "generated"
      },
      {
        "text": "The bananas in the foreground",
        "type": "generated"
      },
      {
        "text": "banana",
        "type": "generated"
      },
      {
        "text": "the bananas",
        "type": "generated"
      },
      {
        "text": "The bunch of bananas",
        "type": "generated"
      },
      {
        "text": "The highlighted object is: a banana",
        "type": "generated"
      },
      {
        "text": "Banana bottom right corner",
        "type": "gold"
      },
      {
        "text": "banana on the bottom right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      44.121330621480645,
      47.134458855951024,
      47.134458855951024,
      44.30211207504678,
      68.26031427662298,
      47.30372638749869,
      47.30372638749869,
      74.8815510833165,
      78.9936296807745,
      53.66528821603408,
      44.12376925735915
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073599983_48.jpg",
    "bbox": [
      325.77118263961376,
      160.28058332789666,
      143.7862184401096,
      81.88392463954854
    ],
    "candidates": [
      {
        "text": "The laptop",
        "type": "generated"
      },
      {
        "text": "laptop",
        "type": "generated"
      },
      {
        "text": "computer screen",
        "type": "generated"
      },
      {
        "text": "the laptop",
        "type": "generated"
      },
      {
        "text": "screen",
        "type": "generated"
      },
      {
        "text": "laptop computer the",
        "type": "generated"
      },
      {
        "text": "The computer",
        "type": "generated"
      },
      {
        "text": "computer",
        "type": "generated"
      },
      {
        "text": "Computer laptop computer",
        "type": "generated"
      },
      {
        "text": "white laptop on right",
        "type": "gold"
      },
      {
        "text": "laptop right",
        "type": "gold"
      },
      {
        "text": "right laptop",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      13.981220275145775,
      23.251540663235346,
      148.35847738247531,
      22.177688136255163,
      16.43936093083602,
      24.524143301602802,
      13.981220275145775,
      22.177688136255163,
      22.336225168239128,
      26.56382954573295,
      7.644808684093131,
      12.23000657163651
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073621243_49.jpg",
    "bbox": [
      119.06405260671977,
      151.3516295189951,
      232.78953801572715,
      164.32417726205065
    ],
    "candidates": [
      {
        "text": "One of the giraffes in front left",
        "type": "generated"
      },
      {
        "text": "The necks and heads of two giraffes",
        "type": "generated"
      },
      {
        "text": "The giraffe in the lower portion of photo",
        "type": "generated"
      },
      {
        "text": "The two giraffes most in the foreground",
        "type": "generated"
      },
      {
        "text": "The two heads of giraffe",
        "type": "generated"
      },
      {
        "text": "The two heads nearest the camera",
        "type": "generated"
      },
      {
        "text": "The giraffe at the bottom of image",
        "type": "generated"
      },
      {
        "text": "The neck and head of the giraffe in",
        "type": "generated"
      },
      {
        "text": "The giraffe's neck and head",
        "type": "generated"
      },
      {
        "text": "closest giraffe",
        "type": "gold"
      },
      {
        "text": "front girafe",
        "type": "gold"
      },
      {
        "text": "parially visible giraffe",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      86.3290878166097,
      88.77670172487036,
      26.038388236294146,
      76.93812593613714,
      88.4051333911927,
      86.59434054113723,
      30.60799193207412,
      83.22406035176475,
      80.20562851214964,
      78.82790754612766,
      87.87789820970028,
      78.82790754612766
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073625810_50.jpg",
    "bbox": [
      324.8000081380208,
      177.65999348958331,
      80.72000122070312,
      139.09999593098956
    ],
    "candidates": [
      {
        "text": "The man sitting on the floor with his back against",
        "type": "generated"
      },
      {
        "text": "The person lying on the floor wearing black clothing",
        "type": "generated"
      },
      {
        "text": "The man kneeling on the floor in front of",
        "type": "generated"
      },
      {
        "text": "The man being propped up",
        "type": "generated"
      },
      {
        "text": "The man in front of the seated guy",
        "type": "generated"
      },
      {
        "text": "The person on the floor",
        "type": "generated"
      },
      {
        "text": "The object highlighted by the red box is: man",
        "type": "generated"
      },
      {
        "text": "The guy in the black shirt",
        "type": "generated"
      },
      {
        "text": "The man on the ground",
        "type": "generated"
      },
      {
        "text": "dude sitting with face covered in black",
        "type": "gold"
      },
      {
        "text": "lower space betwen white shirt girl and brown jacket",
        "type": "gold"
      },
      {
        "text": "BLACK AREA TO RIGHT OF MAN IN TSHIR NEAR LEGS",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      48.573508109895,
      45.40195749953447,
      48.573508109895,
      48.573508109895,
      116.88481601389476,
      43.50102731662823,
      56.3266239109553,
      39.072776381574606,
      45.40195749953447,
      39.072776381574606,
      93.71233387728127,
      44.20987527264545
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073630372_51.jpg",
    "bbox": [
      127.07822105532787,
      168.60327548668033,
      103.97377460846019,
      144.42716719115927
    ],
    "candidates": [
      {
        "text": "The pony with the back leg raised",
        "type": "generated"
      },
      {
        "text": "The horse's left front leg",
        "type": "generated"
      },
      {
        "text": "The horse's back right hoof",
        "type": "generated"
      },
      {
        "text": "The horse",
        "type": "generated"
      },
      {
        "text": "the horse behind jockey in blue helmet",
        "type": "generated"
      },
      {
        "text": "Horse's legs",
        "type": "generated"
      },
      {
        "text": "The horse's leg",
        "type": "generated"
      },
      {
        "text": "The horse on the left",
        "type": "generated"
      },
      {
        "text": "The horse's back left leg",
        "type": "generated"
      },
      {
        "text": "The horse the person in blue is riding.",
        "type": "gold"
      },
      {
        "text": "small light brown horse being ridden by person in blue",
        "type": "gold"
      },
      {
        "text": "horse w/ person in blue on it",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      15.256910064196143,
      22.997565969662602,
      29.964275735309002,
      125.04013333316742,
      28.34424194509938,
      25.20805828585446,
      12.526444506200557,
      18.22831211576851,
      9.33499745498016,
      58.420440719247345,
      22.42812564542394,
      72.49974514153503
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073639487_52.jpg",
    "bbox": [
      239.5800018310547,
      128.47999572753906,
      74.12000274658203,
      78.625
    ],
    "candidates": [
      {
        "text": "The TV with the white band and red box drawn",
        "type": "generated"
      },
      {
        "text": "The television",
        "type": "generated"
      },
      {
        "text": "The TV in the middle",
        "type": "generated"
      },
      {
        "text": "The tube TV",
        "type": "generated"
      },
      {
        "text": "The TV",
        "type": "generated"
      },
      {
        "text": "The old tube TV",
        "type": "generated"
      },
      {
        "text": "The highlighted object is the middle television",
        "type": "generated"
      },
      {
        "text": "A tube television",
        "type": "generated"
      },
      {
        "text": "TV",
        "type": "generated"
      },
      {
        "text": "middle middle tv",
        "type": "gold"
      },
      {
        "text": "middle tv of 3 tv stack",
        "type": "gold"
      },
      {
        "text": "middle tv in set of 3",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      9.086069956346108,
      9.086069956346108,
      7.962706486827531,
      9.086069956346108,
      9.086069956346108,
      5.3375494788447115,
      9.086069956346108,
      7.840810259970921,
      11.99065590242524,
      9.390731442910349,
      10.696850967766881,
      10.696850967766881
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073648384_53.jpg",
    "bbox": [
      93.56853190104167,
      0.0,
      97.51039713541667,
      238.19093750000002
    ],
    "candidates": [
      {
        "text": "It",
        "type": "generated"
      },
      {
        "text": "The first green bottle on the left",
        "type": "generated"
      },
      {
        "text": "The bottle in the background",
        "type": "generated"
      },
      {
        "text": "The bottle in the back left",
        "type": "generated"
      },
      {
        "text": "The bottle in front of the first glass on",
        "type": "generated"
      },
      {
        "text": "The highlighted object of the wine bottles",
        "type": "generated"
      },
      {
        "text": "The bottle behind the first wine glass on left",
        "type": "generated"
      },
      {
        "text": "The bottle to the left of wine glasses in",
        "type": "generated"
      },
      {
        "text": "The bottle with a green image on the label,",
        "type": "generated"
      },
      {
        "text": "green bottle",
        "type": "gold"
      },
      {
        "text": "tall bottle on left says blanc",
        "type": "gold"
      },
      {
        "text": "green back left",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      54.86222648893886,
      23.284066039324486,
      213.95715886906805,
      77.10163896652018,
      102.57381281459523,
      58.16634840974311,
      25.140865763207586,
      79.6949339376326,
      17.709038125308318,
      77.67829382345897,
      23.901889701938295,
      31.370684266104615
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073657495_54.jpg",
    "bbox": [
      17.0,
      0.4186915905676155,
      51.663550261025115,
      315.82804742260515
    ],
    "candidates": [
      {
        "text": "The red box highlights the woman's head",
        "type": "generated"
      },
      {
        "text": "The woman's left ear",
        "type": "generated"
      },
      {
        "text": "The woman",
        "type": "generated"
      },
      {
        "text": "arm",
        "type": "generated"
      },
      {
        "text": "The back of the woman's head",
        "type": "generated"
      },
      {
        "text": "The woman's head",
        "type": "generated"
      },
      {
        "text": "The red box highlights the arm of person in",
        "type": "generated"
      },
      {
        "text": "The back of the head",
        "type": "generated"
      },
      {
        "text": "Man's right shoulder",
        "type": "generated"
      },
      {
        "text": "far left red shirt",
        "type": "gold"
      },
      {
        "text": "far left red sleeve",
        "type": "gold"
      },
      {
        "text": "peron in red on the left, cut off",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      31.897241032912557,
      208.9642323001535,
      210.86924811918584,
      266.34469120063494,
      132.81968893384172,
      206.4457202318149,
      16.97529735437363,
      423.33388354077505,
      384.1251823321843,
      19.77350101366561,
      25.65331531154395,
      19.77350101366561
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073662057_55.jpg",
    "bbox": [
      178.42499923706055,
      58.42499923706055,
      155.3300018310547,
      104.98999786376953
    ],
    "candidates": [
      {
        "text": "Laptop",
        "type": "generated"
      },
      {
        "text": "The laptop",
        "type": "generated"
      },
      {
        "text": "The laptop screen to the right",
        "type": "generated"
      },
      {
        "text": "The Laptop",
        "type": "generated"
      },
      {
        "text": "The laptop in the middle of screen",
        "type": "generated"
      },
      {
        "text": "Laptop computer",
        "type": "generated"
      },
      {
        "text": "The computer",
        "type": "generated"
      },
      {
        "text": "The laptop computer",
        "type": "generated"
      },
      {
        "text": "The laptop displaying the identical screen content as large",
        "type": "generated"
      },
      {
        "text": "bigger screen",
        "type": "gold"
      },
      {
        "text": "bigger screen in the back",
        "type": "gold"
      },
      {
        "text": "bigger computer screen",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      17.284356029587777,
      26.765528994539732,
      62.59385712558019,
      26.765528994539732,
      26.765528994539732,
      6.8405939125413076,
      26.765528994539732,
      24.760165401331584,
      26.765528994539732,
      34.20928491352965,
      14.920269615150971,
      32.932755411330945
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073675501_56.jpg",
    "bbox": [
      58.104000651041666,
      75.50293619791667,
      137.34399739583336,
      180.4970703125
    ],
    "candidates": [
      {
        "text": "The bear on the left",
        "type": "generated"
      },
      {
        "text": "The teddy bear on the far left is highlighted",
        "type": "generated"
      },
      {
        "text": "The bear on the far left",
        "type": "generated"
      },
      {
        "text": "The first two stuffed bears",
        "type": "generated"
      },
      {
        "text": "The third bear from the left",
        "type": "generated"
      },
      {
        "text": "The leftmost bear",
        "type": "generated"
      },
      {
        "text": "The teddy bear on the left",
        "type": "generated"
      },
      {
        "text": "The bear in the front left",
        "type": "generated"
      },
      {
        "text": "The first three bears on the left",
        "type": "generated"
      },
      {
        "text": "bear second from left",
        "type": "gold"
      },
      {
        "text": "2nd from left",
        "type": "gold"
      },
      {
        "text": "second toy from left",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      74.52298907271198,
      73.60867860742746,
      68.04573282970468,
      61.38450575130133,
      102.2822643847157,
      70.71672484637715,
      68.62582553964808,
      38.710240682084155,
      72.13177364840602,
      60.349361639801515,
      61.45943880043879,
      61.64352705406205
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073684478_57.jpg",
    "bbox": [
      108.55424848568985,
      130.87058472477534,
      51.921570223141345,
      108.34510154973448
    ],
    "candidates": [
      {
        "text": "The man's elbow",
        "type": "generated"
      },
      {
        "text": "The shoulder and sleeve of the man next to",
        "type": "generated"
      },
      {
        "text": "The person's arm",
        "type": "generated"
      },
      {
        "text": "The sleeve of the person next to boy",
        "type": "generated"
      },
      {
        "text": "The object highlighted by the red box is folded",
        "type": "generated"
      },
      {
        "text": "The arm and part of the head person",
        "type": "generated"
      },
      {
        "text": "The forearm",
        "type": "generated"
      },
      {
        "text": "The plaid shirt",
        "type": "generated"
      },
      {
        "text": "The plaid-sleeved elbow",
        "type": "generated"
      },
      {
        "text": "checkered shirt",
        "type": "gold"
      },
      {
        "text": "far left person arm only",
        "type": "gold"
      },
      {
        "text": "person in a checked shirt",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      8.518145629351416,
      16.97805109215059,
      9.19173873251905,
      10.731173490921211,
      11.834315159507018,
      123.0365923712754,
      61.396526513745336,
      9.506274644316022,
      8.147475075244326,
      10.497804707893007,
      9.51667354617186,
      9.67640325827528
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073689038_58.jpg",
    "bbox": [
      306.9529411764706,
      0.0,
      110.74258961397058,
      76.9430606617647
    ],
    "candidates": [
      {
        "text": "The shoes",
        "type": "generated"
      },
      {
        "text": "Jeans",
        "type": "generated"
      },
      {
        "text": "The jeans",
        "type": "generated"
      },
      {
        "text": "The legs and bottom part of a person's jeans",
        "type": "generated"
      },
      {
        "text": "The person's legs",
        "type": "generated"
      },
      {
        "text": "The legs",
        "type": "generated"
      },
      {
        "text": "The crossed legs",
        "type": "generated"
      },
      {
        "text": "The legs of a person",
        "type": "generated"
      },
      {
        "text": "His pants legs",
        "type": "generated"
      },
      {
        "text": "blue jeans man on the right",
        "type": "gold"
      },
      {
        "text": "jeans on right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      28.212279519757146,
      176.5129859356988,
      176.00260555539836,
      181.3985288102537,
      23.64250460370484,
      179.82550094939515,
      178.55460019423873,
      177.8210247720866,
      175.77685557662815,
      5.229549294017293,
      5.574760912390911
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073698004_59.jpg",
    "bbox": [
      105.35000038146973,
      114.33499908447266,
      132.31500244140625,
      136.6300048828125
    ],
    "candidates": [
      {
        "text": "The highlighted donut",
        "type": "generated"
      },
      {
        "text": "Pink frosted",
        "type": "generated"
      },
      {
        "text": "A pink donut",
        "type": "generated"
      },
      {
        "text": "The pink frosted donut",
        "type": "generated"
      },
      {
        "text": "The doughnut with pink frosting",
        "type": "generated"
      },
      {
        "text": "The pink frosted doughnut",
        "type": "generated"
      },
      {
        "text": "The donut with pink frosting and white sprinkles",
        "type": "generated"
      },
      {
        "text": "The pink donut",
        "type": "generated"
      },
      {
        "text": "A pink frosted doughnut",
        "type": "generated"
      },
      {
        "text": "pinke/red donut",
        "type": "gold"
      },
      {
        "text": "pink",
        "type": "gold"
      },
      {
        "text": "pink donut",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      21.752697956684944,
      16.258463893012458,
      17.015222748810558,
      17.015222748810558,
      12.479474994130962,
      17.015222748810558,
      21.752697956684944,
      17.8082147815907,
      19.457072182782678,
      16.258463893012458,
      21.10962702931155,
      16.258463893012458
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073707786_60.jpg",
    "bbox": [
      337.22744810814953,
      133.0352902879902,
      130.87058871400123,
      104.98823577282475
    ],
    "candidates": [
      {
        "text": "The zebra in the second from right position",
        "type": "generated"
      },
      {
        "text": "The zebra in the back",
        "type": "generated"
      },
      {
        "text": "The zebra in the back right",
        "type": "generated"
      },
      {
        "text": "The zebra facing away from the viewers",
        "type": "generated"
      },
      {
        "text": "The zebra in front",
        "type": "generated"
      },
      {
        "text": "The zebra in front of the larger",
        "type": "generated"
      },
      {
        "text": "The zebra on the right side of group",
        "type": "generated"
      },
      {
        "text": "zebras in the back",
        "type": "generated"
      },
      {
        "text": "The female zebra",
        "type": "generated"
      },
      {
        "text": "right most zebra",
        "type": "gold"
      },
      {
        "text": "R Z",
        "type": "gold"
      },
      {
        "text": "right zebra",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      149.87703153486473,
      54.11689205169845,
      47.63142129228276,
      49.84054052705298,
      144.2711788136453,
      144.37666696412035,
      17.941677656350798,
      54.168354688812755,
      128.96742546167474,
      17.01427350963514,
      149.87703153486473,
      17.77158466876557
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073717581_61.jpg",
    "bbox": [
      188.913330078125,
      76.36000061035156,
      119.71333821614583,
      168.7266642252604
    ],
    "candidates": [
      {
        "text": "The zebra in the middle",
        "type": "generated"
      },
      {
        "text": "The middle zebra",
        "type": "generated"
      },
      {
        "text": "The zebra on the middle left",
        "type": "generated"
      },
      {
        "text": "The zebra in the center",
        "type": "generated"
      },
      {
        "text": "The zebra in the center of image",
        "type": "generated"
      },
      {
        "text": "Middle zebra",
        "type": "generated"
      },
      {
        "text": "the middle zebra",
        "type": "generated"
      },
      {
        "text": "The zebra",
        "type": "generated"
      },
      {
        "text": "The zebra in the middle of picture",
        "type": "generated"
      },
      {
        "text": "middle zebra",
        "type": "gold"
      },
      {
        "text": "zebra standing in the middle",
        "type": "gold"
      },
      {
        "text": "center zebra",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      24.16777731892988,
      18.59916387194053,
      106.43171624286606,
      22.3863132329194,
      22.3863132329194,
      21.086952370529165,
      9.0597043311927,
      28.35141986644819,
      25.292241067047275,
      21.086952370529165,
      17.21755237413644,
      49.943444210842614
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073736807_62.jpg",
    "bbox": [
      16.0,
      66.87699438820422,
      254.56526921948355,
      225.79530241343895
    ],
    "candidates": [
      {
        "text": "The first giraffe on the left",
        "type": "generated"
      },
      {
        "text": "The giraffe on the right",
        "type": "generated"
      },
      {
        "text": "The giraffe on the left",
        "type": "generated"
      },
      {
        "text": "The smaller giraffe in the left part of",
        "type": "generated"
      },
      {
        "text": "The giraffe with only its head visible",
        "type": "generated"
      },
      {
        "text": "The giraffe in the left rectangle",
        "type": "generated"
      },
      {
        "text": "The giraffe looking left",
        "type": "generated"
      },
      {
        "text": "The giraffe to the right",
        "type": "generated"
      },
      {
        "text": "The giraffe with darker brown spots",
        "type": "generated"
      },
      {
        "text": "left giraffe",
        "type": "gold"
      },
      {
        "text": "giraffe on left",
        "type": "gold"
      },
      {
        "text": "L giraffe",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      35.20927023324596,
      277.51908444335487,
      29.49897917611484,
      24.695401023942228,
      134.69910882817385,
      25.96135487805322,
      62.94389529726788,
      265.05665993204974,
      211.84041822102142,
      33.22931854737618,
      29.49897917611484,
      45.93652478732086
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073746473_63.jpg",
    "bbox": [
      250.14352022058824,
      1.4381176219267005,
      118.65599724264706,
      219.32424172794117
    ],
    "candidates": [
      {
        "text": "The man",
        "type": "generated"
      },
      {
        "text": "The cake",
        "type": "generated"
      },
      {
        "text": "The person in the red box is one wearing",
        "type": "generated"
      },
      {
        "text": "The man in the center with grey hair",
        "type": "generated"
      },
      {
        "text": "The man in the military uniform",
        "type": "generated"
      },
      {
        "text": "the person on right",
        "type": "generated"
      },
      {
        "text": "The person in the red box appears to be referring",
        "type": "generated"
      },
      {
        "text": "The person in the military uniform",
        "type": "generated"
      },
      {
        "text": "The man in the middle",
        "type": "generated"
      },
      {
        "text": "man to the most right",
        "type": "gold"
      },
      {
        "text": "army guy behind redhead",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      76.63488309646948,
      115.58664722663144,
      78.47996514919537,
      73.19811178684814,
      127.02220141176062,
      61.51230071609949,
      78.47996514919537,
      125.39136740281593,
      73.19811178684814,
      76.59322393257783,
      71.57767772226285
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073756220_64.jpg",
    "bbox": [
      294.8301932856722,
      187.0867919921875,
      93.33584767467572,
      120.83019328567218
    ],
    "candidates": [
      {
        "text": "The dishwasher",
        "type": "generated"
      },
      {
        "text": "The dishwasher's door",
        "type": "generated"
      },
      {
        "text": "dishwasher",
        "type": "generated"
      },
      {
        "text": "the dishwasher",
        "type": "generated"
      },
      {
        "text": "Below the plate, but above drawer handle in",
        "type": "generated"
      },
      {
        "text": "The dishwasher under the countertop to left of",
        "type": "generated"
      },
      {
        "text": "washer",
        "type": "generated"
      },
      {
        "text": "Dishwasher",
        "type": "generated"
      },
      {
        "text": "Under the sink cabinet on right",
        "type": "generated"
      },
      {
        "text": "dishwasher",
        "type": "gold"
      },
      {
        "text": "black dishwasher",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      48.60648386898808,
      48.28205764432942,
      44.12719626318439,
      48.60648386898808,
      117.76452349863655,
      275.3929926616236,
      44.088633479794225,
      48.60648386898808,
      47.84636131442731,
      44.12719626318439,
      44.4818006116363
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073774619_65.jpg",
    "bbox": [
      247.93000030517578,
      31.655000686645508,
      104.75,
      149.9550018310547
    ],
    "candidates": [
      {
        "text": "The person holding the baby",
        "type": "generated"
      },
      {
        "text": "The man holding the baby",
        "type": "generated"
      },
      {
        "text": "Man with baby",
        "type": "generated"
      },
      {
        "text": "The baby",
        "type": "generated"
      },
      {
        "text": "The man feeding the baby",
        "type": "generated"
      },
      {
        "text": "The man holding baby",
        "type": "generated"
      },
      {
        "text": "Man with arm around baby",
        "type": "generated"
      },
      {
        "text": "man holding baby",
        "type": "generated"
      },
      {
        "text": "A man with a baby",
        "type": "generated"
      },
      {
        "text": "blue guy",
        "type": "gold"
      },
      {
        "text": "blue shirt rightmost",
        "type": "gold"
      },
      {
        "text": "guy blue shirt",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      25.34254460285652,
      32.017781480546915,
      36.75251086839327,
      25.560558654783875,
      30.14581851928675,
      26.30003600799799,
      39.9142552412468,
      25.498513275335476,
      25.560558654783875,
      29.83375070302546,
      25.568434047151815,
      35.29166377813636
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073783993_66.jpg",
    "bbox": [
      188.01764634076287,
      39.588237089269306,
      155.7588285558364,
      170.32941032858457
    ],
    "candidates": [
      {
        "text": "The man on the right",
        "type": "generated"
      },
      {
        "text": "The man in the middle wearing blue t-shirt",
        "type": "generated"
      },
      {
        "text": "The man between the elephants",
        "type": "generated"
      },
      {
        "text": "The man on the left",
        "type": "generated"
      },
      {
        "text": "The person on the top elephant",
        "type": "generated"
      },
      {
        "text": "The man on the elephant",
        "type": "generated"
      },
      {
        "text": "The middle one",
        "type": "generated"
      },
      {
        "text": "The man who is grooming the elephant's tusk",
        "type": "generated"
      },
      {
        "text": "The man in the middle",
        "type": "generated"
      },
      {
        "text": "elephant driver",
        "type": "gold"
      },
      {
        "text": "guy in black",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      64.14730577022469,
      49.287011927936796,
      69.25352052413501,
      148.45748136748028,
      146.00190836333883,
      68.71661181186272,
      68.71661181186272,
      27.37573083609491,
      68.71661181186272,
      45.08415665580833,
      46.31965364221309
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073788796_67.jpg",
    "bbox": [
      247.79434742647058,
      50.80847311580882,
      196.0357536764706,
      79.28470818014706
    ],
    "candidates": [
      {
        "text": "laptop",
        "type": "generated"
      },
      {
        "text": "Apple laptop",
        "type": "generated"
      },
      {
        "text": "The Mac laptop",
        "type": "generated"
      },
      {
        "text": "The MacBook",
        "type": "generated"
      },
      {
        "text": "Apple Mac laptop",
        "type": "generated"
      },
      {
        "text": "The Mac",
        "type": "generated"
      },
      {
        "text": "The computer",
        "type": "generated"
      },
      {
        "text": "The laptop on top of the orange microwave",
        "type": "generated"
      },
      {
        "text": "Macbook",
        "type": "generated"
      },
      {
        "text": "apple laptop",
        "type": "gold"
      },
      {
        "text": "apple pc",
        "type": "gold"
      },
      {
        "text": "macbook laptop",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      157.056255768292,
      16.314441187159005,
      16.314441187159005,
      13.836679411319148,
      14.948381244720277,
      13.681824549890113,
      156.6366999087637,
      12.39200817234187,
      14.849243774045688,
      17.001734948212487,
      17.001734948212487,
      16.213598742735883
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073798291_68.jpg",
    "bbox": [
      149.30000019073486,
      113.04000091552734,
      222.75,
      64.83000183105469
    ],
    "candidates": [
      {
        "text": "The cat with white fur on its neck",
        "type": "generated"
      },
      {
        "text": "Area where the cat is lying",
        "type": "generated"
      },
      {
        "text": "The cat",
        "type": "generated"
      },
      {
        "text": "The cat in the back",
        "type": "generated"
      },
      {
        "text": "The cat at the top of image",
        "type": "generated"
      },
      {
        "text": "The cat at the top of bed",
        "type": "generated"
      },
      {
        "text": "Top cat",
        "type": "generated"
      },
      {
        "text": "The top cat",
        "type": "generated"
      },
      {
        "text": "The highlighted element in the room",
        "type": "generated"
      },
      {
        "text": "top animal",
        "type": "gold"
      },
      {
        "text": "cat in back",
        "type": "gold"
      },
      {
        "text": "top cat",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      75.32385111980132,
      8.345761706129244,
      60.37900848218223,
      8.305650284173648,
      5.327882452912781,
      7.983216193943607,
      6.7252774816726735,
      5.145987224059241,
      6.7252774816726735,
      6.7252774816726735,
      28.227542673931424,
      6.7252774816726735
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073807960_69.jpg",
    "bbox": [
      179.67527857497166,
      37.115647365717116,
      121.80317504606009,
      270.99137701955783
    ],
    "candidates": [
      {
        "text": "The opened refrigerator",
        "type": "generated"
      },
      {
        "text": "fridge",
        "type": "generated"
      },
      {
        "text": "refrigerator door",
        "type": "generated"
      },
      {
        "text": "The refrigerator",
        "type": "generated"
      },
      {
        "text": "Refrigerator",
        "type": "generated"
      },
      {
        "text": "The door of the refrigerator",
        "type": "generated"
      },
      {
        "text": "The left refrigerator",
        "type": "generated"
      },
      {
        "text": "The refrigerator on the right",
        "type": "generated"
      },
      {
        "text": "Refrigerator door",
        "type": "generated"
      },
      {
        "text": "closed fridge between the lady and open doored one",
        "type": "gold"
      },
      {
        "text": "the fridge the sign is cutting into",
        "type": "gold"
      },
      {
        "text": "middle fridge",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      135.4009632908378,
      130.4685953359288,
      40.50252047175912,
      137.57717117740688,
      121.6294177444286,
      145.23215515017765,
      173.23705150228318,
      129.63072868470334,
      41.653311805984096,
      39.71228390876142,
      40.286137637038244,
      36.377127428363764
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073817009_70.jpg",
    "bbox": [
      43.72000002861023,
      147.086669921875,
      194.44000244140625,
      139.19332885742188
    ],
    "candidates": [
      {
        "text": "A woman on the left",
        "type": "generated"
      },
      {
        "text": "The woman on the left",
        "type": "generated"
      },
      {
        "text": "woman on the left",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "The woman with the short black hair and long",
        "type": "generated"
      },
      {
        "text": "The woman with her hair tied back in a bun",
        "type": "generated"
      },
      {
        "text": "The person on the left",
        "type": "generated"
      },
      {
        "text": "The lady with the black top",
        "type": "generated"
      },
      {
        "text": "The girl on the left",
        "type": "generated"
      },
      {
        "text": "girl in black",
        "type": "gold"
      },
      {
        "text": "LEFT GIRL",
        "type": "gold"
      },
      {
        "text": "left person",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      49.06049513625577,
      49.69887481294504,
      48.10666946564767,
      50.19148957384638,
      49.69887481294504,
      49.69887481294504,
      49.69887481294504,
      50.69797930401836,
      49.69887481294504,
      48.41049052174121,
      49.69887481294504,
      49.69887481294504
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073826658_71.jpg",
    "bbox": [
      418.07954963235295,
      132.41223575367647,
      78.8028262867647,
      148.93176700367647
    ],
    "candidates": [
      {
        "text": "The woman sitting at the table",
        "type": "generated"
      },
      {
        "text": "The woman in camouflage",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "The woman in the red box is on far",
        "type": "generated"
      },
      {
        "text": "The person highlighted by the red box",
        "type": "generated"
      },
      {
        "text": "The woman in the chair",
        "type": "generated"
      },
      {
        "text": "The person in the red box",
        "type": "generated"
      },
      {
        "text": "The woman on the far right",
        "type": "generated"
      },
      {
        "text": "The woman sitting at the far end of table",
        "type": "generated"
      },
      {
        "text": "right woman sitting",
        "type": "gold"
      },
      {
        "text": "person sitting",
        "type": "gold"
      },
      {
        "text": "sitting down",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      46.7228537869949,
      350.0645058995233,
      237.76173181192718,
      44.30162471029128,
      48.040735921235054,
      46.48077372673778,
      47.82725917391815,
      47.72840200768078,
      46.7228537869949,
      51.82235173365627,
      50.54188241886205,
      50.883321629873336
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073836935_72.jpg",
    "bbox": [
      412.13334147135413,
      142.55999755859375,
      57.53333536783854,
      177.44000244140625
    ],
    "candidates": [
      {
        "text": "The person sitting in a red box",
        "type": "generated"
      },
      {
        "text": "The person on the right",
        "type": "generated"
      },
      {
        "text": "The person highlighting the box",
        "type": "generated"
      },
      {
        "text": "The man on the right",
        "type": "generated"
      },
      {
        "text": "The man in the red box",
        "type": "generated"
      },
      {
        "text": "GENTLEMAN IN Blue short-sleeved",
        "type": "generated"
      },
      {
        "text": "The guy sitting down on the right",
        "type": "generated"
      },
      {
        "text": "The man sitting",
        "type": "generated"
      },
      {
        "text": "The man in the blue shirt",
        "type": "generated"
      },
      {
        "text": "right guy",
        "type": "gold"
      },
      {
        "text": "guy on right cut off",
        "type": "gold"
      },
      {
        "text": "person right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      62.48514835320282,
      66.86150508025351,
      65.8011238869388,
      66.08668986951356,
      64.400224844594,
      365.378616241987,
      64.400224844594,
      64.68941063098552,
      368.39726324602253,
      65.26732805620868,
      67.86822408146367,
      64.88808195392481
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073846757_73.jpg",
    "bbox": [
      336.71943153542156,
      54.4299745224678,
      130.15830832845435,
      261.0360710626464
    ],
    "candidates": [
      {
        "text": "The man with the baseball bat",
        "type": "generated"
      },
      {
        "text": "The object highlighted by the red box is billboard",
        "type": "generated"
      },
      {
        "text": "The man in the poster",
        "type": "generated"
      },
      {
        "text": "The man with the bat",
        "type": "generated"
      },
      {
        "text": "poster in the background",
        "type": "generated"
      },
      {
        "text": "The man with a bat",
        "type": "generated"
      },
      {
        "text": "The guy in the poster",
        "type": "generated"
      },
      {
        "text": "The man holding a baseball bat",
        "type": "generated"
      },
      {
        "text": "The man holding a bat",
        "type": "generated"
      },
      {
        "text": "guy on right",
        "type": "gold"
      },
      {
        "text": "man on right",
        "type": "gold"
      },
      {
        "text": "man with hammer in back",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      67.94567294206054,
      102.24990624185183,
      99.06611964805741,
      99.3602376250451,
      99.29620382043308,
      99.3602376250451,
      99.11972375808796,
      57.20994470176459,
      59.731301544955265,
      99.3602376250451,
      102.53489203802621,
      67.94408360538601
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073856399_74.jpg",
    "bbox": [
      185.42823988970588,
      97.79952895220588,
      181.93318014705883,
      217.8861213235294
    ],
    "candidates": [
      {
        "text": "The child",
        "type": "generated"
      },
      {
        "text": "The little girl",
        "type": "generated"
      },
      {
        "text": "The highlighted object is: little girl in pink",
        "type": "generated"
      },
      {
        "text": "The daughter",
        "type": "generated"
      },
      {
        "text": "The little girl in pink",
        "type": "generated"
      },
      {
        "text": "The girl",
        "type": "generated"
      },
      {
        "text": "Her",
        "type": "generated"
      },
      {
        "text": "The highlighted child",
        "type": "generated"
      },
      {
        "text": "The baby girl",
        "type": "generated"
      },
      {
        "text": "baby on lap",
        "type": "gold"
      },
      {
        "text": "baby on man lap",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      53.16731160371942,
      53.16731160371942,
      53.208380499713506,
      169.51891229591618,
      53.16731160371942,
      169.96493088001816,
      53.16731160371942,
      53.208380499713506,
      53.16731160371942,
      49.98114603341999,
      53.236289817378704
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073865650_75.jpg",
    "bbox": [
      47.193333307902016,
      130.48000081380206,
      144.98000081380206,
      101.24666341145833
    ],
    "candidates": [
      {
        "text": "The sheep in the middle left of image",
        "type": "generated"
      },
      {
        "text": "The sheep on the left",
        "type": "generated"
      },
      {
        "text": "The sheep on the right",
        "type": "generated"
      },
      {
        "text": "That sheep",
        "type": "generated"
      },
      {
        "text": "The sheep in the upper left",
        "type": "generated"
      },
      {
        "text": "The sheep in the foreground with a black head",
        "type": "generated"
      },
      {
        "text": "The sheep in the center",
        "type": "generated"
      },
      {
        "text": "The sheep in the foreground",
        "type": "generated"
      },
      {
        "text": "Sheep with black face",
        "type": "generated"
      },
      {
        "text": "left goat",
        "type": "gold"
      },
      {
        "text": "ram on way left",
        "type": "gold"
      },
      {
        "text": "Far left sheep",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      34.8337366980942,
      30.47268896791825,
      283.90540418172134,
      48.11503967011065,
      38.47107939607396,
      283.06722814454434,
      136.9286536630941,
      136.9286536630941,
      100.70837063986036,
      13.889687485350226,
      33.170114559630754,
      33.38360133129657
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073875265_76.jpg",
    "bbox": [
      186.17898404396186,
      150.15050648834745,
      49.13898222325212,
      110.23728813559322
    ],
    "candidates": [
      {
        "text": "The player in the middle of front row",
        "type": "generated"
      },
      {
        "text": "The girl wearing a white t-shirt with rainbow",
        "type": "generated"
      },
      {
        "text": "The person in the center of photo",
        "type": "generated"
      },
      {
        "text": "The woman in the middle",
        "type": "generated"
      },
      {
        "text": "The person in the middle of first row sitting",
        "type": "generated"
      },
      {
        "text": "Linda Hansen",
        "type": "generated"
      },
      {
        "text": "The person in the middle of front row",
        "type": "generated"
      },
      {
        "text": "The person in the center of front row,",
        "type": "generated"
      },
      {
        "text": "The person",
        "type": "generated"
      },
      {
        "text": "lower row, second from left",
        "type": "gold"
      },
      {
        "text": "bottom row second from left",
        "type": "gold"
      },
      {
        "text": "Gwynne Morris",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      35.78494670552946,
      36.74192128598314,
      35.78494670552946,
      36.670053841676896,
      35.78494670552946,
      58.41672452163195,
      35.78494670552946,
      35.78494670552946,
      36.74192128598314,
      50.977843988018336,
      55.39250604141406,
      111.44857194797524
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073880320_77.jpg",
    "bbox": [
      279.25499725341797,
      31.75,
      53.61000061035156,
      260.8399963378906
    ],
    "candidates": [
      {
        "text": "The woman",
        "type": "generated"
      },
      {
        "text": "The woman's right arm",
        "type": "generated"
      },
      {
        "text": "The woman in the center",
        "type": "generated"
      },
      {
        "text": "The woman's gesture",
        "type": "generated"
      },
      {
        "text": "The lady holding the horse's head",
        "type": "generated"
      },
      {
        "text": "The lady holding up her hand",
        "type": "generated"
      },
      {
        "text": "The woman on the right",
        "type": "generated"
      },
      {
        "text": "The woman's outstretched hand",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "winner",
        "type": "gold"
      },
      {
        "text": "woman",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      66.17622773507597,
      66.17622773507597,
      62.97312963846872,
      116.0906735656751,
      60.06009876465106,
      66.17622773507597,
      66.17622773507597,
      114.81068109553064,
      66.17622773507597,
      66.17622773507597,
      66.17622773507597
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073890312_78.jpg",
    "bbox": [
      0.6480000019073486,
      52.23999938964844,
      321.16000976562503,
      244.447998046875
    ],
    "candidates": [
      {
        "text": "The woman seated on the couch holding a glass of",
        "type": "generated"
      },
      {
        "text": "The woman on the couch holding wine glass",
        "type": "generated"
      },
      {
        "text": "The woman on the couch",
        "type": "generated"
      },
      {
        "text": "The woman lying on the couch",
        "type": "generated"
      },
      {
        "text": "The frame",
        "type": "generated"
      },
      {
        "text": "The woman leaning against the sofa",
        "type": "generated"
      },
      {
        "text": "The image in the red box",
        "type": "generated"
      },
      {
        "text": "The lady",
        "type": "generated"
      },
      {
        "text": "The woman holding the glass of wine",
        "type": "generated"
      },
      {
        "text": "woman in purple",
        "type": "gold"
      },
      {
        "text": "woman",
        "type": "gold"
      },
      {
        "text": "purple shirt",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      38.688872842865194,
      46.72906273481256,
      126.50524639911886,
      35.29596983846342,
      125.40756136041024,
      134.3179385978347,
      132.00946571866712,
      134.3179385978347,
      41.464529778284046,
      78.8119778209172,
      132.00946571866712,
      78.70494718720076
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073900189_79.jpg",
    "bbox": [
      300.88999938964844,
      70.83999633789062,
      72.3550033569336,
      93.72000122070312
    ],
    "candidates": [
      {
        "text": "The man holding the bucket",
        "type": "generated"
      },
      {
        "text": "The man in the background on right",
        "type": "generated"
      },
      {
        "text": "The man with a pot in his arms",
        "type": "generated"
      },
      {
        "text": "An old man",
        "type": "generated"
      },
      {
        "text": "The man with the apron and bucket",
        "type": "generated"
      },
      {
        "text": "The man standing at a table",
        "type": "generated"
      },
      {
        "text": "The man under the red box",
        "type": "generated"
      },
      {
        "text": "the man",
        "type": "generated"
      },
      {
        "text": "The person in the red box",
        "type": "generated"
      },
      {
        "text": "guy in the back emptying container",
        "type": "gold"
      },
      {
        "text": "right guy",
        "type": "gold"
      },
      {
        "text": "man in the back",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      14.070875496307428,
      28.800961481044084,
      7.318125326549499,
      22.907600124905812,
      2.957919964068503,
      14.12359282641406,
      21.732903403769708,
      23.07674016355722,
      15.88400050310326,
      3.1466309932346763,
      30.05111935386243,
      30.05111935386243
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073905101_80.jpg",
    "bbox": [
      77.08213216145833,
      35.797333984375,
      132.98346354166668,
      151.27040364583334
    ],
    "candidates": [
      {
        "text": "Carrots",
        "type": "generated"
      },
      {
        "text": "The contents of the left purple tub",
        "type": "generated"
      },
      {
        "text": "The orange oval container of cut carrots",
        "type": "generated"
      },
      {
        "text": "the carrots",
        "type": "generated"
      },
      {
        "text": "The carrots",
        "type": "generated"
      },
      {
        "text": "The container of small orange squares",
        "type": "generated"
      },
      {
        "text": "The orange bowl at the top left containing carrot slices",
        "type": "generated"
      },
      {
        "text": "The highlighted food item is baby carrots",
        "type": "generated"
      },
      {
        "text": "The food item that was mentioned as potentially being carriage",
        "type": "generated"
      },
      {
        "text": "left orange",
        "type": "gold"
      },
      {
        "text": "carrots",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      23.06380589563531,
      18.133262003609325,
      16.23033923628446,
      23.06380589563531,
      16.271020375446902,
      15.373213150093516,
      20.99557232826821,
      19.876970532709667,
      23.06380589563531,
      16.271020375446902,
      23.06380589563531
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073915017_81.jpg",
    "bbox": [
      311.5765835406909,
      85.86791706308549,
      103.45667676009954,
      234.13209437207263
    ],
    "candidates": [
      {
        "text": "The old man",
        "type": "generated"
      },
      {
        "text": "The older man in the white shirt with gray hair",
        "type": "generated"
      },
      {
        "text": "the older man",
        "type": "generated"
      },
      {
        "text": "The man with gray hair and a white shirt",
        "type": "generated"
      },
      {
        "text": "The older man with gray hair",
        "type": "generated"
      },
      {
        "text": "The man with the gray hair and white shirt",
        "type": "generated"
      },
      {
        "text": "The man with gray hair",
        "type": "generated"
      },
      {
        "text": "man in the orange t-shirt",
        "type": "generated"
      },
      {
        "text": "The gentleman wearing the white shirt",
        "type": "generated"
      },
      {
        "text": "white hair man",
        "type": "gold"
      },
      {
        "text": "white shirt tasting",
        "type": "gold"
      },
      {
        "text": "guy i white",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      70.2253416972835,
      71.88525556847001,
      71.52523520868094,
      74.06176579490575,
      89.57963844992189,
      72.82866446927639,
      80.49359546905177,
      53.91967018862074,
      13.239208189458617,
      79.55844020124026,
      13.239208189458617,
      70.4714670730143
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073924719_82.jpg",
    "bbox": [
      54.280000050862625,
      162.39333089192706,
      154.66666666666666,
      127.34666951497395
    ],
    "candidates": [
      {
        "text": "The laptop",
        "type": "generated"
      },
      {
        "text": "The laptop to the left",
        "type": "generated"
      },
      {
        "text": "The laptop on the left",
        "type": "generated"
      },
      {
        "text": "Laptop on the left",
        "type": "generated"
      },
      {
        "text": "The laptop with the red box around it",
        "type": "generated"
      },
      {
        "text": "Laptop",
        "type": "generated"
      },
      {
        "text": "The laptop on the left side with an open screen",
        "type": "generated"
      },
      {
        "text": "The laptop with the picture of family",
        "type": "generated"
      },
      {
        "text": "The laptop on the far left side of desk",
        "type": "generated"
      },
      {
        "text": "laptop furthest left",
        "type": "gold"
      },
      {
        "text": "L LAP",
        "type": "gold"
      },
      {
        "text": "left laptop",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      36.23173233535159,
      36.23173233535159,
      36.23173233535159,
      37.059193247786865,
      36.23173233535159,
      37.059193247786865,
      36.23173233535159,
      123.84945781236345,
      36.23173233535159,
      41.125761994583684,
      34.25775659050532,
      42.49905758636178
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073934351_83.jpg",
    "bbox": [
      177.87353629976582,
      0.20983606646714223,
      111.0332580137588,
      143.25058090603045
    ],
    "candidates": [
      {
        "text": "The woman in white",
        "type": "generated"
      },
      {
        "text": "The woman in the white polka dot shirt",
        "type": "generated"
      },
      {
        "text": "The woman in the polka dot shirt",
        "type": "generated"
      },
      {
        "text": "The woman in the middle",
        "type": "generated"
      },
      {
        "text": "The woman's face",
        "type": "generated"
      },
      {
        "text": "The woman in the middle wearing a white shirt with",
        "type": "generated"
      },
      {
        "text": "The woman in the white flowery blouse",
        "type": "generated"
      },
      {
        "text": "The lady in the polka dot shirt with a",
        "type": "generated"
      },
      {
        "text": "The woman in a white shirt with brown polka",
        "type": "generated"
      },
      {
        "text": "Center polka",
        "type": "gold"
      },
      {
        "text": "black dotted on white",
        "type": "gold"
      },
      {
        "text": "woman in pokodots",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      26.091777339988603,
      26.178638075452632,
      26.178638075452632,
      26.178638075452632,
      38.83931423679218,
      26.178638075452632,
      26.178638075452632,
      26.178638075452632,
      17.44043230374174,
      15.543706970365559,
      145.02596898844237,
      18.05486599787857
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073943916_84.jpg",
    "bbox": [
      406.47492498536303,
      130.33817192988877,
      89.15035060194673,
      137.34520226507613
    ],
    "candidates": [
      {
        "text": "The vehicle surrounded by a red square is referred to",
        "type": "generated"
      },
      {
        "text": "The bus",
        "type": "generated"
      },
      {
        "text": "The front tip of the bus",
        "type": "generated"
      },
      {
        "text": "The front part of the bus on right end",
        "type": "generated"
      },
      {
        "text": "The bus with the number 382 on",
        "type": "generated"
      },
      {
        "text": "Bus number 972",
        "type": "generated"
      },
      {
        "text": "Bus number 792",
        "type": "generated"
      },
      {
        "text": "The bus at the end",
        "type": "generated"
      },
      {
        "text": "Bus number 646",
        "type": "generated"
      },
      {
        "text": "Greenish bus on right",
        "type": "gold"
      },
      {
        "text": "right most car",
        "type": "gold"
      },
      {
        "text": "smallest bus",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      23.01078348357498,
      154.61146038689452,
      94.39734469221128,
      1.3094100853154198,
      111.46424046064921,
      105.69453582321053,
      105.69453582321053,
      21.69818736439364,
      199.9172159120481,
      25.177475059904957,
      23.01078348357498,
      23.435662607069943
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073948684_85.jpg",
    "bbox": [
      193.7184418613471,
      0.0,
      90.01165001137743,
      137.50679090185074
    ],
    "candidates": [
      {
        "text": "Man in white t-shirt",
        "type": "generated"
      },
      {
        "text": "The area of the person's arm between elbow",
        "type": "generated"
      },
      {
        "text": "His white shirt",
        "type": "generated"
      },
      {
        "text": "The partially visible person",
        "type": "generated"
      },
      {
        "text": "The person's midsection",
        "type": "generated"
      },
      {
        "text": "The body of a man walking",
        "type": "generated"
      },
      {
        "text": "The person's white t-shirt",
        "type": "generated"
      },
      {
        "text": "The person's torso",
        "type": "generated"
      },
      {
        "text": "The man standing",
        "type": "generated"
      },
      {
        "text": "white shirt",
        "type": "gold"
      },
      {
        "text": "man white shirt middle",
        "type": "gold"
      },
      {
        "text": "person in the white shirt",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      16.286143782312585,
      21.43498082647075,
      25.881415570944444,
      8.331367753862544,
      79.73498871883241,
      129.67333904081732,
      22.68254705869698,
      79.73498871883241,
      7.34171865557214,
      27.161037614757916,
      34.19946450252289,
      22.68254705869698
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073953457_86.jpg",
    "bbox": [
      275.7933349609375,
      217.30000813802081,
      81.44000244140625,
      99.46000162760416
    ],
    "candidates": [
      {
        "text": "Woman petting cow",
        "type": "generated"
      },
      {
        "text": "The girl",
        "type": "generated"
      },
      {
        "text": "The little girl",
        "type": "generated"
      },
      {
        "text": "The person who is milking one of the cows",
        "type": "generated"
      },
      {
        "text": "The woman examining the rope around cow's head",
        "type": "generated"
      },
      {
        "text": "The girl writing something",
        "type": "generated"
      },
      {
        "text": "The lady in the green shirt",
        "type": "generated"
      },
      {
        "text": "The girl painting the cow's face",
        "type": "generated"
      },
      {
        "text": "The girl petting the cow",
        "type": "generated"
      },
      {
        "text": "little girl yellow head band",
        "type": "gold"
      },
      {
        "text": "kid middle right front",
        "type": "gold"
      },
      {
        "text": "left girl",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      24.163166989784585,
      185.773247201105,
      17.56153977852971,
      24.083732086747176,
      24.163166989784585,
      114.09018103939188,
      27.079312602388587,
      139.1951166102564,
      11.236706137011382,
      34.9395768973793,
      17.882799679940533,
      144.91263645087298
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073958331_87.jpg",
    "bbox": [
      367.8666585286458,
      28.64666748046875,
      64.53999837239583,
      248.42667643229166
    ],
    "candidates": [
      {
        "text": "The woman on the right",
        "type": "generated"
      },
      {
        "text": "The woman standing next to the lady in striped",
        "type": "generated"
      },
      {
        "text": "The person in the green shirt with red box",
        "type": "generated"
      },
      {
        "text": "Woman with curly red hair",
        "type": "generated"
      },
      {
        "text": "The woman with short brown curly hair, glasses,",
        "type": "generated"
      },
      {
        "text": "The woman in the black vest",
        "type": "generated"
      },
      {
        "text": "The woman with the red box around her",
        "type": "generated"
      },
      {
        "text": "The woman wearing curly hair",
        "type": "generated"
      },
      {
        "text": "The woman with curly red hair",
        "type": "generated"
      },
      {
        "text": "a woman with glasses wearing a black t-shirt",
        "type": "gold"
      },
      {
        "text": "glasses right",
        "type": "gold"
      },
      {
        "text": "far rt woman",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      93.41413707174306,
      143.95240654634225,
      89.12909802981515,
      96.5904811113224,
      94.00755812624004,
      89.12909802981515,
      94.00755812624004,
      96.3184713012864,
      96.71804541199502,
      96.71804541199502,
      97.70555819561511,
      96.5904811113224
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073963116_88.jpg",
    "bbox": [
      302.1399943033854,
      153.92666625976562,
      167.34666951497394,
      94.33999633789062
    ],
    "candidates": [
      {
        "text": "The beds",
        "type": "generated"
      },
      {
        "text": "The sofas",
        "type": "generated"
      },
      {
        "text": "The sofa bed",
        "type": "generated"
      },
      {
        "text": "The sofa beds",
        "type": "generated"
      },
      {
        "text": "The bed",
        "type": "generated"
      },
      {
        "text": "The highlighted object can be referred to as:",
        "type": "generated"
      },
      {
        "text": "The couches",
        "type": "generated"
      },
      {
        "text": "The sofa (or sofas)",
        "type": "generated"
      },
      {
        "text": "The sofa",
        "type": "generated"
      },
      {
        "text": "bed close to window",
        "type": "gold"
      },
      {
        "text": "bed by window",
        "type": "gold"
      },
      {
        "text": "back bed",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      24.763389925139503,
      21.492456888045496,
      13.723681589345649,
      21.805884152159802,
      11.755093727965082,
      25.513054701856255,
      23.917532043311525,
      21.805884152159802,
      13.246392184175846,
      19.7414757612071,
      24.552644201862265,
      16.278516170385284
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073972459_89.jpg",
    "bbox": [
      16.801873575608123,
      170.8964820879684,
      244.81125128073774,
      149.10351791203163
    ],
    "candidates": [
      {
        "text": "The slice",
        "type": "generated"
      },
      {
        "text": "The icing",
        "type": "generated"
      },
      {
        "text": "The chocolate frosted donut top",
        "type": "generated"
      },
      {
        "text": "The donut piece",
        "type": "generated"
      },
      {
        "text": "The top of the cake",
        "type": "generated"
      },
      {
        "text": "The topping on the right doughnut",
        "type": "generated"
      },
      {
        "text": "The bottom left portion of the donut",
        "type": "generated"
      },
      {
        "text": "The cream-filled donut with chopped nuts",
        "type": "generated"
      },
      {
        "text": "Crumble topping",
        "type": "generated"
      },
      {
        "text": "partial donut bottom left",
        "type": "gold"
      },
      {
        "text": "bottom left food",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      37.716513143379366,
      173.08242369520485,
      243.34649863070098,
      173.46307298465288,
      247.27503816120577,
      283.51574008901946,
      40.04435244554245,
      41.08662506627358,
      34.78504939354498,
      34.64510937097586,
      29.234946283284167
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073977249_90.jpg",
    "bbox": [
      87.00827833153735,
      1.4344827936983657,
      195.15586835488506,
      113.36092403017241
    ],
    "candidates": [
      {
        "text": "Top",
        "type": "generated"
      },
      {
        "text": "Top left donut",
        "type": "generated"
      },
      {
        "text": "The donut",
        "type": "generated"
      },
      {
        "text": "The donut with pink pearls in the upper left",
        "type": "generated"
      },
      {
        "text": "Top donut",
        "type": "generated"
      },
      {
        "text": "The donut with pink dots",
        "type": "generated"
      },
      {
        "text": "The highlighted donut",
        "type": "generated"
      },
      {
        "text": "Top sprinkled donut",
        "type": "generated"
      },
      {
        "text": "The tan ring",
        "type": "generated"
      },
      {
        "text": "top left white",
        "type": "gold"
      },
      {
        "text": "back light tan donut with brown flakes",
        "type": "gold"
      },
      {
        "text": "white donut",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      17.594389476667764,
      32.233403579388074,
      37.95443146584334,
      24.930803062449606,
      22.933478186136636,
      24.930803062449606,
      33.07937290358224,
      32.41615002790106,
      38.705238846882864,
      23.620955987138494,
      42.356026000006366,
      28.382635264419786
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073986371_91.jpg",
    "bbox": [
      240.07085372740966,
      97.48048051581326,
      217.73108057228916,
      122.35565700301206
    ],
    "candidates": [
      {
        "text": "The player diving for the frisbee",
        "type": "generated"
      },
      {
        "text": "guy diving for it",
        "type": "generated"
      },
      {
        "text": "The man diving for the frisbee",
        "type": "generated"
      },
      {
        "text": "the guy",
        "type": "generated"
      },
      {
        "text": "The guy in the white shirt, blue pants,",
        "type": "generated"
      },
      {
        "text": "The man who dove and is on the grass",
        "type": "generated"
      },
      {
        "text": "The character doing the diving catch for fris",
        "type": "generated"
      },
      {
        "text": "The guy on the ground trying to catch fr",
        "type": "generated"
      },
      {
        "text": "guy on the ground",
        "type": "generated"
      },
      {
        "text": "diving guy",
        "type": "gold"
      },
      {
        "text": "man catching frisbee",
        "type": "gold"
      },
      {
        "text": "boy diving on right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      95.93058675308421,
      71.13319924947642,
      95.93058675308421,
      52.63247357659548,
      60.139848604436274,
      60.139848604436274,
      60.139848604436274,
      60.139848604436274,
      55.351273742013475,
      56.34588580395187,
      96.76473211567074,
      65.46524519159638
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749073996524_92.jpg",
    "bbox": [
      105.35000038146973,
      114.33499908447266,
      132.31500244140625,
      136.6300048828125
    ],
    "candidates": [
      {
        "text": "The donut",
        "type": "generated"
      },
      {
        "text": "The pink frosted doughnut",
        "type": "generated"
      },
      {
        "text": "The doughnut with pink icing and possibly a cherry",
        "type": "generated"
      },
      {
        "text": "The doughnut with pink frosting",
        "type": "generated"
      },
      {
        "text": "The donut with pink glaze",
        "type": "generated"
      },
      {
        "text": "The pink glazed donut in the center",
        "type": "generated"
      },
      {
        "text": "The donut in the bottom left",
        "type": "generated"
      },
      {
        "text": "The highlighted donut",
        "type": "generated"
      },
      {
        "text": "The pink frosted donut",
        "type": "generated"
      },
      {
        "text": "pinke/red donut",
        "type": "gold"
      },
      {
        "text": "pink",
        "type": "gold"
      },
      {
        "text": "pink donut",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      127.09825032186374,
      17.015222748810558,
      14.790342896773543,
      12.479474994130962,
      21.752697956684944,
      17.015222748810558,
      113.20658279586326,
      21.752697956684944,
      17.015222748810558,
      16.258463893012458,
      21.10962702931155,
      16.258463893012458
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074001201_93.jpg",
    "bbox": [
      275.7007152090827,
      11.01582698684802,
      115.57409931429855,
      305.55397088579133
    ],
    "candidates": [
      {
        "text": "The woman",
        "type": "generated"
      },
      {
        "text": "The woman in the blue bikini",
        "type": "generated"
      },
      {
        "text": "She",
        "type": "generated"
      },
      {
        "text": "The woman in blue",
        "type": "generated"
      },
      {
        "text": "The woman wearing the blue bikini",
        "type": "generated"
      },
      {
        "text": "The lady",
        "type": "generated"
      },
      {
        "text": "girl",
        "type": "generated"
      },
      {
        "text": "The woman in the bikini",
        "type": "generated"
      },
      {
        "text": "The woman in blue bikini",
        "type": "generated"
      },
      {
        "text": "tan lines on butt",
        "type": "gold"
      },
      {
        "text": "girl throwing frisbee",
        "type": "gold"
      },
      {
        "text": "right person",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      101.18385086349747,
      139.15070488602896,
      100.79244848539798,
      139.778777609832,
      22.819791742888526,
      101.18385086349747,
      101.18385086349747,
      139.778777609832,
      139.778777609832,
      20.459278769759457,
      47.47194197998089,
      99.38478196538695
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074010172_94.jpg",
    "bbox": [
      96.0,
      88.66999816894531,
      137.97999572753906,
      207.05999755859375
    ],
    "candidates": [
      {
        "text": "A banana",
        "type": "generated"
      },
      {
        "text": "The bunch of bananas",
        "type": "generated"
      },
      {
        "text": "The bunch to the left",
        "type": "generated"
      },
      {
        "text": "The bunch of bananas above the parrot's head",
        "type": "generated"
      },
      {
        "text": "The bunch of bananas to the left",
        "type": "generated"
      },
      {
        "text": "The bunch of bananas to the left par",
        "type": "generated"
      },
      {
        "text": "banans",
        "type": "generated"
      },
      {
        "text": "The bunch of unripe yellow bananas",
        "type": "generated"
      },
      {
        "text": "The bunch nearest the camera",
        "type": "generated"
      },
      {
        "text": "Far left center banana",
        "type": "gold"
      },
      {
        "text": "banana left bird is standing on",
        "type": "gold"
      },
      {
        "text": "bananas that the parrot to left sitting on",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      53.541139737854685,
      119.93861665148644,
      49.74035583555097,
      74.99168578326521,
      33.03783164405589,
      31.962159025709305,
      48.6249080563756,
      43.37288659538331,
      150.7483533773785,
      35.73886370636637,
      80.85229256252406,
      62.52290843680601
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074019279_95.jpg",
    "bbox": [
      286.6066691080729,
      52.973332722981766,
      65.58000183105469,
      201.80000813802081
    ],
    "candidates": [
      {
        "text": "the board",
        "type": "generated"
      },
      {
        "text": "The snowboard in the man's left hand",
        "type": "generated"
      },
      {
        "text": "The snowboard",
        "type": "generated"
      },
      {
        "text": "The object highlighted by the red box is referred to",
        "type": "generated"
      },
      {
        "text": "The person holding the black snowboard",
        "type": "generated"
      },
      {
        "text": "The snowboard in the man's hands",
        "type": "generated"
      },
      {
        "text": "The snowboard he's carrying",
        "type": "generated"
      },
      {
        "text": "The person in the red rectangle",
        "type": "generated"
      },
      {
        "text": "The person highlighted by the red box",
        "type": "generated"
      },
      {
        "text": "Left guy",
        "type": "gold"
      },
      {
        "text": "left dude",
        "type": "gold"
      },
      {
        "text": "left man",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      42.38282443555633,
      43.449263448156174,
      47.228462056019325,
      80.91338833579363,
      42.38282443555633,
      41.65091018437993,
      7.611590514895389,
      80.92969957726548,
      80.28983000712292,
      50.35283944637361,
      50.35283944637361,
      50.35283944637361
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074028394_96.jpg",
    "bbox": [
      214.99500274658203,
      146.17999267578125,
      43.46500015258789,
      109.9800033569336
    ],
    "candidates": [
      {
        "text": "The young child in black clothing",
        "type": "generated"
      },
      {
        "text": "The child in the black suit",
        "type": "generated"
      },
      {
        "text": "The child",
        "type": "generated"
      },
      {
        "text": "The person in black",
        "type": "generated"
      },
      {
        "text": "The boy in front",
        "type": "generated"
      },
      {
        "text": "The boy carrying the kite",
        "type": "generated"
      },
      {
        "text": "The Son",
        "type": "generated"
      },
      {
        "text": "Son",
        "type": "generated"
      },
      {
        "text": "The boy",
        "type": "generated"
      },
      {
        "text": "child in black, back to us",
        "type": "gold"
      },
      {
        "text": "KID",
        "type": "gold"
      },
      {
        "text": "little kid in black jacket. back to us",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      39.236652059679095,
      39.236652059679095,
      72.86551503862788,
      32.95856394198546,
      34.210567412202025,
      34.210567412202025,
      72.2284880713356,
      70.31773112630098,
      43.02075338128035,
      25.50497645238462,
      69.68092506545331,
      15.905569447891354
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074037233_97.jpg",
    "bbox": [
      309.54667154947913,
      50.38666788736979,
      120.63333129882812,
      171.1933390299479
    ],
    "candidates": [
      {
        "text": "The baby bear",
        "type": "generated"
      },
      {
        "text": "The cub on the right side of image",
        "type": "generated"
      },
      {
        "text": "The cub on the right",
        "type": "generated"
      },
      {
        "text": "The bear on the right",
        "type": "generated"
      },
      {
        "text": "The last cub",
        "type": "generated"
      },
      {
        "text": "The bear to the right",
        "type": "generated"
      },
      {
        "text": "Leftmost cub",
        "type": "generated"
      },
      {
        "text": "The bear cub on the right",
        "type": "generated"
      },
      {
        "text": "The baby bear on the right",
        "type": "generated"
      },
      {
        "text": "animal on right",
        "type": "gold"
      },
      {
        "text": "the baby bear on right",
        "type": "gold"
      },
      {
        "text": "bear on right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      17.670081397855988,
      8.396818061932128,
      8.396818061932128,
      8.680885276870653,
      66.24531260101996,
      8.680885276870653,
      162.13135400174815,
      18.108075378088117,
      17.670081397855988,
      8.396818061932128,
      17.670081397855988,
      12.49895834920613
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074046207_98.jpg",
    "bbox": [
      316.15334065755206,
      91.89333089192708,
      131.89333089192706,
      171.5333251953125
    ],
    "candidates": [
      {
        "text": "The zebra with its tail closest to the viewer",
        "type": "generated"
      },
      {
        "text": "The zebra behind another",
        "type": "generated"
      },
      {
        "text": "The zebra in the red box",
        "type": "generated"
      },
      {
        "text": "The zebra near the brown brush",
        "type": "generated"
      },
      {
        "text": "To the upper right of zebra on",
        "type": "generated"
      },
      {
        "text": "The zebra on the right",
        "type": "generated"
      },
      {
        "text": "The zebra in the red box would be referred",
        "type": "generated"
      },
      {
        "text": "The zebra with its head turned to the right",
        "type": "generated"
      },
      {
        "text": "The zebra towards the right side of image",
        "type": "generated"
      },
      {
        "text": "last zebra facing to right",
        "type": "gold"
      },
      {
        "text": "right back zebra",
        "type": "gold"
      },
      {
        "text": "back right zbra head",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      54.86289626370579,
      158.83541731204704,
      10.159244403930987,
      18.75033662876847,
      65.87653974816935,
      11.162692642255738,
      10.159244403930987,
      11.162692642255738,
      47.099876100602785,
      12.693042829655504,
      50.94065905975434,
      60.76686561174162
    ]
  },
  {
    "image_path": "output/overlayed_images/overlayed_example_1749074055310_99.jpg",
    "bbox": [
      361.05292191159253,
      103.86885703307964,
      94.50116981667155,
      188.28290809792156
    ],
    "candidates": [
      {
        "text": "The man with the long hair",
        "type": "generated"
      },
      {
        "text": "The man on the far right",
        "type": "generated"
      },
      {
        "text": "the man",
        "type": "generated"
      },
      {
        "text": "The guy in the pink shirt and black pants",
        "type": "generated"
      },
      {
        "text": "The man eating a snack",
        "type": "generated"
      },
      {
        "text": "The guy eating the chips",
        "type": "generated"
      },
      {
        "text": "The guy in the pink shirt",
        "type": "generated"
      },
      {
        "text": "the guy in pink t-shirt and black trousers",
        "type": "generated"
      },
      {
        "text": "The man on the couch",
        "type": "generated"
      },
      {
        "text": "LAST PERSON ON RIGHT",
        "type": "gold"
      },
      {
        "text": "girl on right eating",
        "type": "gold"
      },
      {
        "text": "last person on far right",
        "type": "gold"
      }
    ],
    "gaze_distances": [
      64.87375964744088,
      65.26013845943592,
      66.9083525508258,
      62.88698868013388,
      63.011785375744545,
      60.33476681205174,
      61.64513726876812,
      63.273070592520696,
      63.63206027172079,
      68.35302233749293,
      65.93655980696906,
      68.35302233749293
    ]
  }
]